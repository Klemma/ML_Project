{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт необходимых зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from random import random, sample\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from functools import reduce\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/seq2seq-dataset/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemm_texts</th>\n",
       "      <th>orig_texts</th>\n",
       "      <th>nsubj</th>\n",
       "      <th>gender</th>\n",
       "      <th>tense</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>я предлагать оригинальный подарок для малыш!</td>\n",
       "      <td>я предлагаю оригинальный подарок для малыша!</td>\n",
       "      <td>я</td>\n",
       "      <td>undefined</td>\n",
       "      <td>pres</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>я обезательный перезвонить в любой случай.</td>\n",
       "      <td>я обезательно перезвоню в любом случае.</td>\n",
       "      <td>я</td>\n",
       "      <td>undefined</td>\n",
       "      <td>fut</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>цена на память я не помнить.</td>\n",
       "      <td>цены на память я не помню.</td>\n",
       "      <td>я</td>\n",
       "      <td>undefined</td>\n",
       "      <td>pres</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>я не помнить , где находиться.</td>\n",
       "      <td>я не помню, где находились.</td>\n",
       "      <td>я</td>\n",
       "      <td>undefined</td>\n",
       "      <td>pres</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>я работать на высококачественный американский ...</td>\n",
       "      <td>я работаю на высококачественных американских м...</td>\n",
       "      <td>я</td>\n",
       "      <td>undefined</td>\n",
       "      <td>pres</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356967</th>\n",
       "      <td>другой ящерица медленно подбрести к свой товарка.</td>\n",
       "      <td>другая ящерица медленно подбрела к своей товарке.</td>\n",
       "      <td>ящерица</td>\n",
       "      <td>fem</td>\n",
       "      <td>past</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356968</th>\n",
       "      <td>зелёный ящерица застылый на мраморный ступень.</td>\n",
       "      <td>зеленая ящерица застыла на мраморной ступени.</td>\n",
       "      <td>ящерица</td>\n",
       "      <td>fem</td>\n",
       "      <td>past</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356969</th>\n",
       "      <td>больший ящерица шмыгнуть по песок.</td>\n",
       "      <td>большая ящерица шмыгнула по песку.</td>\n",
       "      <td>ящерица</td>\n",
       "      <td>fem</td>\n",
       "      <td>past</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356970</th>\n",
       "      <td>домашний ящерица быстро пробежать вдоль штора.</td>\n",
       "      <td>домашняя ящерица быстро пробежала вдоль штор.</td>\n",
       "      <td>ящерица</td>\n",
       "      <td>fem</td>\n",
       "      <td>past</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356971</th>\n",
       "      <td>крошечный ящерка сбежать с валун.</td>\n",
       "      <td>крошечная ящерка сбежала с валуна.</td>\n",
       "      <td>ящерка</td>\n",
       "      <td>fem</td>\n",
       "      <td>past</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356972 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lemm_texts  \\\n",
       "0            я предлагать оригинальный подарок для малыш!   \n",
       "1              я обезательный перезвонить в любой случай.   \n",
       "2                            цена на память я не помнить.   \n",
       "3                          я не помнить , где находиться.   \n",
       "4       я работать на высококачественный американский ...   \n",
       "...                                                   ...   \n",
       "356967  другой ящерица медленно подбрести к свой товарка.   \n",
       "356968     зелёный ящерица застылый на мраморный ступень.   \n",
       "356969                 больший ящерица шмыгнуть по песок.   \n",
       "356970     домашний ящерица быстро пробежать вдоль штора.   \n",
       "356971                  крошечный ящерка сбежать с валун.   \n",
       "\n",
       "                                               orig_texts    nsubj     gender  \\\n",
       "0            я предлагаю оригинальный подарок для малыша!        я  undefined   \n",
       "1                 я обезательно перезвоню в любом случае.        я  undefined   \n",
       "2                              цены на память я не помню.        я  undefined   \n",
       "3                             я не помню, где находились.        я  undefined   \n",
       "4       я работаю на высококачественных американских м...        я  undefined   \n",
       "...                                                   ...      ...        ...   \n",
       "356967  другая ящерица медленно подбрела к своей товарке.  ящерица        fem   \n",
       "356968      зеленая ящерица застыла на мраморной ступени.  ящерица        fem   \n",
       "356969                 большая ящерица шмыгнула по песку.  ящерица        fem   \n",
       "356970      домашняя ящерица быстро пробежала вдоль штор.  ящерица        fem   \n",
       "356971                 крошечная ящерка сбежала с валуна.   ящерка        fem   \n",
       "\n",
       "       tense number  \n",
       "0       pres   sing  \n",
       "1        fut   sing  \n",
       "2       pres   sing  \n",
       "3       pres   sing  \n",
       "4       pres   sing  \n",
       "...      ...    ...  \n",
       "356967  past   sing  \n",
       "356968  past   sing  \n",
       "356969  past   sing  \n",
       "356970  past   sing  \n",
       "356971  past   sing  \n",
       "\n",
       "[356972 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение классов словаря и трансформера текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens: List[str], unk_idx: int):\n",
    "        self._tokens = tokens\n",
    "        self._token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
    "        self._unk_idx = unk_idx\n",
    "        \n",
    "    def token_to_idx(self, token: str) -> int:\n",
    "        return self._token_to_idx.get(token, self._unk_idx)\n",
    "    \n",
    "    def idx_to_token(self, idx: int) -> str:\n",
    "        return self._tokens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTransformer:\n",
    "    def __init__(self, vocab_size: int):\n",
    "        self.vocab = None\n",
    "        self.vocab_size = vocab_size\n",
    "        self.special_tokens_to_idx = {'<UNK>': 0, '<PAD>': 1, '<SOS>': 2, '<EOS>': 3}\n",
    "        self._tokenizer = nltk.tokenize.wordpunct_tokenize\n",
    "    \n",
    "    def tokenize(self, text) -> List[str]:\n",
    "        return self._tokenizer(text.lower())\n",
    "    \n",
    "    def build_vocab(self, tokens: List[str]):\n",
    "        tokens_ = [special_token for special_token in self.special_tokens_to_idx.keys()]\n",
    "        special_tokens_amount = len(self.special_tokens_to_idx)\n",
    "        \n",
    "        for token, _ in Counter(tokens).most_common(self.vocab_size - special_tokens_amount):\n",
    "            tokens_.append(token)\n",
    "        \n",
    "        unk_idx = self.special_tokens_to_idx.get('<UNK>')\n",
    "        self.vocab = Vocab(tokens_, unk_idx)\n",
    "        \n",
    "    def transform_text(self, text: str) -> List[int]:\n",
    "        tokenized_text = self.tokenize(text)\n",
    "        transformed = [self.vocab.token_to_idx(token) for token in tokenized_text]\n",
    "        return transformed\n",
    "    \n",
    "    def fit_transform(self, texts: List[str]) -> None:\n",
    "        transformed_texts = []\n",
    "        \n",
    "        tokenized_texts = [self.tokenize(text) for text in tqdm(texts, 'Tokenizing texts')]\n",
    "        tokens = chain(*tokenized_texts)\n",
    "        self.build_vocab(tokens)\n",
    "        \n",
    "        for tokenized_text in tqdm(tokenized_texts, 'Transforming texts'):\n",
    "            transformed = [self.vocab.token_to_idx(token) for token in tokenized_text]\n",
    "            transformed_texts.append(transformed)\n",
    "    \n",
    "    def transform_texts(self, texts: List[str]) -> List[List[int]]:\n",
    "        transformed_texts = [transform_text(text) for text in tqdm(texts, 'Transforming texts')]\n",
    "        return transformed_texts\n",
    "    \n",
    "    def text_to_tensor(self, text: str, max_seq_len=8) -> torch.tensor:\n",
    "        transformed_text = self.transform_text(text)\n",
    "        pad_idx = self.special_tokens_to_idx.get('<PAD>')\n",
    "        sos_idx = self.special_tokens_to_idx.get('<SOS>')\n",
    "        eos_idx = self.special_tokens_to_idx.get('<EOS>')\n",
    "        \n",
    "        pad_size = 0\n",
    "        if len(transformed_text) >= max_seq_len:\n",
    "            transformed_text = transformed_text[:max_seq_len]\n",
    "        else:\n",
    "            pad_size = max_seq_len - len(transformed_text)\n",
    "            transformed_text.extend([pad_idx] * pad_size)   \n",
    "        transformed_text.insert(0, sos_idx)\n",
    "        transformed_text.insert(len(transformed_text) - pad_size, eos_idx)\n",
    "        \n",
    "        tensor = torch.tensor(transformed_text, dtype=torch.long)\n",
    "        return tensor.unsqueeze(0)\n",
    "    \n",
    "    def texts_to_tensor(self, texts: List[str], max_seq_len=8) -> torch.tensor:\n",
    "        pad_idx = self.special_tokens_to_idx.get('<PAD>')\n",
    "        sos_idx = self.special_tokens_to_idx.get('<SOS>')\n",
    "        eos_idx = self.special_tokens_to_idx.get('<EOS>')\n",
    "        transformed_texts = []\n",
    "        \n",
    "        for text in tqdm(texts, 'Building tensor'):\n",
    "            transformed_text = self.transform_text(text)\n",
    "            pad_size = 0\n",
    "            if len(transformed_text) >= max_seq_len:\n",
    "                transformed_text = transformed_text[:max_seq_len]\n",
    "            else:\n",
    "                pad_size = max_seq_len - len(transformed_text)\n",
    "                transformed_text.extend([pad_idx] * pad_size)   \n",
    "            transformed_text.insert(0, sos_idx)\n",
    "            transformed_text.insert(len(transformed_text) - pad_size, eos_idx)\n",
    "            transformed_texts.append(transformed_text)\n",
    "        \n",
    "        tensor = torch.tensor(transformed_texts, dtype=torch.long).permute(1, 0)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных на обучающую, тестовую и валидационную выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = model_selection.train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, val_df = model_selection.train_test_split(test_df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация текстов и индексация токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_vocab_size = 35000\n",
    "orig_vocab_size = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_text_transformer = TextTransformer(lemm_vocab_size)\n",
    "orig_text_transformer = TextTransformer(orig_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362dfd01d9c14bc398b2e3ad37ef43ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing texts:   0%|          | 0/321274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f8daf0ddc84a6a8cd52ccee78a87cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transforming texts:   0%|          | 0/321274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemm_text_transformer.fit_transform(train_df.lemm_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702c253837d14522b9f1faf619b3737e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing texts:   0%|          | 0/321274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9745ae5f0ecf42348e5098a3ce398003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transforming texts:   0%|          | 0/321274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_text_transformer.fit_transform(train_df.orig_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перевод данных в тензоры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc72a1f85be4dfc9fc5ab4945fe07ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/321274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375689823ce749f6a75bf4d4a1556403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/17849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b87a66e21fa495296378aee4656915e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/17849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_lemm_tensor = lemm_text_transformer.texts_to_tensor(train_df.lemm_texts.to_list())\n",
    "test_lemm_tensor = lemm_text_transformer.texts_to_tensor(test_df.lemm_texts.to_list())\n",
    "val_lemm_tensor = lemm_text_transformer.texts_to_tensor(val_df.lemm_texts.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8469b549cee042ad84808c4e0acb20f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/321274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b670861a2e5e47568022a2370fbfc271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/17849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91f3ae3e1304fbf9f59e0e497cad214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/17849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_orig_tensor = orig_text_transformer.texts_to_tensor(train_df.orig_texts.to_list())\n",
    "test_orig_tensor = orig_text_transformer.texts_to_tensor(test_df.orig_texts.to_list())\n",
    "val_orig_tensor = orig_text_transformer.texts_to_tensor(val_df.orig_texts.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_to_fit_batch(tensor: torch.Tensor, batch_size: int):\n",
    "    n_samples = tensor.shape[1]\n",
    "    new_n_samples = (n_samples // batch_size) * batch_size\n",
    "    result, _ = tensor.split(new_n_samples, dim=1)\n",
    "    return torch.transpose(result, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, hidden_size: int, pad_idx: int,\n",
    "                 device, num_layers, dropout_p: float):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Embedding(vocab_size, embedding_size, pad_idx),\n",
    "            nn.Dropout(dropout_p)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x_shape: (seq_len, batch_size)\n",
    "        embedding = self.embedding(x)\n",
    "        # embedding_shape: (seq_len, batch_size, embedding_size)\n",
    "        output, (hidden, cell) = self.lstm(embedding)\n",
    "        # output_shape: (seq_len, batch_size, hidden_size)\n",
    "        # hidden_shape: (num_layers, batch_size, hidden_size)\n",
    "        # cell_shape: (num_layers, batch_size, hidden_size)\n",
    "        return hidden, cell\n",
    "    \n",
    "    def init_hidden_state(self, batch_size: int):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, hidden_size: int, output_size: int, pad_idx: int,\n",
    "                 device, num_layers, dropout_p: float):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Embedding(vocab_size, embedding_size, pad_idx),\n",
    "            nn.Dropout(dropout_p)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_p)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x_shape: (seq_len=1, batch_size)\n",
    "        # hidden_shape: (num_layers, batch_size, hidden_size)\n",
    "        # cell_shape: (num_layers, batch_size, hidden_size)\n",
    "        embedding = self.embedding(x)\n",
    "        # embedding_shape: (seq_len=1, batch_size, embedding_size)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
    "        # lstm_out_shape: (seq_len=1, batch_size, hidden_size)\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        # fc_out_shape: (seq_len=1, batch_size, output_size)\n",
    "        output = self.softmax(fc_out)\n",
    "        # output_shape: (seq_len=1, batch_size, output_size)\n",
    "        \n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, encoder_vocab_size: int, decoder_vocab_size: int, embedding_size: int, hidden_size: int, output_size: int,\n",
    "                 pad_idx: int, device, num_layers, dropout_p: float):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.encoder = EncoderRNN(encoder_vocab_size, embedding_size, hidden_size, pad_idx, device, num_layers, dropout_p).to(device)\n",
    "        self.decoder = DecoderRNN(decoder_vocab_size, embedding_size, hidden_size, output_size, pad_idx, device, num_layers, dropout_p).to(device)\n",
    "        self.decoder_vocab_size = decoder_vocab_size\n",
    "        \n",
    "    def forward(self, input, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = input.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = self.decoder_vocab_size\n",
    "        \n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size, device=self.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(input)\n",
    "        # hidden, cell shapes: (num_layers, batch_size, hidden_size)\n",
    "        \n",
    "        prev_token_idx = target[0]\n",
    "        # prev_token_shape: (batch_size)\n",
    "        \n",
    "        for t in range(target_len):\n",
    "            output, hidden, cell = self.decoder(prev_token_idx, hidden, cell)\n",
    "            outputs[t] = output.squeeze(0)\n",
    "            \n",
    "            best_prediction = outputs[t].argmax(dim=1)\n",
    "            # best_prediction_shape: (batch_size)\n",
    "            prev_token_idx = target[t] if random() < teacher_forcing_ratio else best_prediction\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция сохранения текущего состояния модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: Seq2SeqModel, optimizer, epoch, path):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'criterion': criterion,\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    \n",
    "#     torch.save(checkpoint, path)\n",
    "    with open(path, mode='wb') as f:\n",
    "        pickle.dump(checkpoint, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция загрузки уже тренировавшейся модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model: Seq2SeqModel, optimizer, criterion, path):\n",
    "    with open(path, mode='rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "#     checkpoint = torch.load(path)\n",
    "        \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    criterion = checkpoint['criterion']\n",
    "    \n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs_amount = 15\n",
    "lemm_vocab_size = 35000\n",
    "orig_vocab_size = 60000\n",
    "hidden_size = 1024\n",
    "embedding_size = 300\n",
    "num_layers = 2\n",
    "max_norm = 1.0\n",
    "dropout_p = 0.4\n",
    "patience = 3\n",
    "output_size = orig_vocab_size\n",
    "pad_idx = lemm_text_transformer.special_tokens_to_idx.get('<PAD>')\n",
    "model_path = './models/'\n",
    "model_name = 'simple_seq2seq.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(lemm_vocab_size, orig_vocab_size, embedding_size, hidden_size, output_size, pad_idx, device, num_layers, dropout_p).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No models found at ./seq2seq.model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    epoch = load_model(model, optimizer, criterion, model_path + model_name)\n",
    "    print(f'Loaded model from {model_path}')\n",
    "except:\n",
    "    print(f'No models found at {model_path}')\n",
    "    epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урезание данных для соответствия размеру батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lemm_tensor_f = cut_to_fit_batch(train_lemm_tensor, batch_size)\n",
    "train_orig_tensor_f = cut_to_fit_batch(train_orig_tensor, batch_size)\n",
    "\n",
    "test_lemm_tensor_f = cut_to_fit_batch(test_lemm_tensor, batch_size)\n",
    "test_orig_tensor_f = cut_to_fit_batch(test_orig_tensor, batch_size)\n",
    "\n",
    "val_lemm_tensor_f = cut_to_fit_batch(val_lemm_tensor, batch_size)\n",
    "val_orig_tensor_f = cut_to_fit_batch(val_orig_tensor, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация данных итерируемых по батчам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_lemm_tensor_f, train_orig_tensor_f)\n",
    "test_dataset = TensorDataset(test_lemm_tensor_f, test_orig_tensor_f)\n",
    "val_dataset = TensorDataset(val_lemm_tensor_f, val_orig_tensor_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение функции проверки работы сети между эпохами обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate(model, input, target_len=8):\n",
    "    input = input.to(device)\n",
    "    sos_idx = lemm_text_transformer.special_tokens_to_idx.get('<SOS>')\n",
    "    eos_idx = lemm_text_transformer.special_tokens_to_idx.get('<EOS>')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        hidden, cell = model.encoder(input)\n",
    "        \n",
    "        predicted_indexes = [sos_idx]\n",
    "        \n",
    "        for _ in range(1, target_len):\n",
    "            prev_idx = torch.tensor([predicted_indexes[-1]], dtype=torch.long, device=device)\n",
    "            \n",
    "            output, hidden, cell = model.decoder(prev_idx, hidden, cell)\n",
    "            output = output.squeeze(0)\n",
    "            \n",
    "            best_prediction = output.argmax(dim=1).item()\n",
    "            \n",
    "            if best_prediction == eos_idx:\n",
    "                break\n",
    "                \n",
    "            predicted_indexes.append(best_prediction)\n",
    "                        \n",
    "        \n",
    "    predicted_tokens = [orig_text_transformer.vocab.idx_to_token(idx) for idx in predicted_indexes]\n",
    "    return predicted_tokens[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение функции обучения сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_data, val_data, test_data, epochs_amount, max_norm, patience=3, current_epoch=1, n_prints=5):\n",
    "    min_mean_val_loss = float('+inf')\n",
    "    initial_patiece = patience\n",
    "    print_every = len(train_data) // n_prints\n",
    "    \n",
    "    for epoch in tqdm(range(current_epoch, epochs_amount + 1), 'Epochs'):\n",
    "        print(f'\\nEpoch [{epoch} / {epochs_amount}]')\n",
    "        epoch_start_time = torch.cuda.Event(enable_timing=True)\n",
    "        epoch_end_time = torch.cuda.Event(enable_timing=True)\n",
    "        epoch_start_time.record()\n",
    "        \n",
    "        model.train()\n",
    "        for iteration, (input, target) in enumerate(tqdm(train_data, 'Epoch training iterations')):\n",
    "            optimizer.zero_grad()\n",
    "            # input = lemm_texts, target = orig_texts\n",
    "            input = torch.transpose(input, 1, 0).to(device)\n",
    "            # input_shape: (seq_len, batch_size)\n",
    "            target = torch.transpose(target, 1, 0).to(device)\n",
    "            # target_shape: (seq_len, batch_size)\n",
    "            output = model(input, target)\n",
    "            # output_shape: (seq_len, batch_size, orig_vocab_size) but need (N, orig_vocab_size)\n",
    "            target = target[1:].reshape(-1)\n",
    "            # now target_shape is (seq_len * batch_size)\n",
    "            orig_vocab_size = output.shape[2]\n",
    "            output = output[1:].reshape(-1, orig_vocab_size)\n",
    "            # now output_shape is (seq_len * batch_size, orig_vocab_size)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration % print_every == 0:\n",
    "                print(f'\\tIteration #{iteration}: training loss = {loss.item()}')\n",
    "            elif iteration == len(train_data):\n",
    "                print(f'\\tIteration #{iteration}: training loss = {loss.item()}')\n",
    "            \n",
    "            \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_loss = []\n",
    "            \n",
    "            for input, target in tqdm(val_data, 'Epoch validating iterations'):\n",
    "                input = torch.transpose(input, 1, 0).to(device)\n",
    "                target = torch.transpose(target, 1, 0).to(device)\n",
    "                \n",
    "                output = model(input, target)\n",
    "                orig_vocab_size = output.shape[2]\n",
    "                output = output[1:].reshape(-1, orig_vocab_size)\n",
    "                target = target[1:].reshape(-1)\n",
    "                \n",
    "                val_loss.append(criterion(output, target).item())\n",
    "            \n",
    "            mean_val_loss = sum(val_loss) / len(val_loss)\n",
    "            print(f'\\tValidation loss = {mean_val_loss}')\n",
    "            if mean_val_loss < min_mean_val_loss:\n",
    "                try:\n",
    "                    save_model(model, optimizer, epoch, model_path)\n",
    "                    min_mean_val_loss = mean_val_loss\n",
    "                    patience = initial_patiece\n",
    "                except Exception as exc:\n",
    "                    print(exc)\n",
    "            else:\n",
    "                patience -= 1\n",
    "            \n",
    "            test_data = DataLoader(test_data.dataset, batch_size=1, shuffle=True)\n",
    "            for input, target in test_data:\n",
    "                target = target.squeeze(0).to(device)\n",
    "                \n",
    "                input = torch.transpose(input, 1, 0)\n",
    "                target_len = target.shape[0]\n",
    "                \n",
    "                output = test_evaluate(model, input, target_len)\n",
    "                decoded_input = [lemm_text_transformer.vocab.idx_to_token(idx.item()) for idx in input]\n",
    "                decoded_target = [orig_text_transformer.vocab.idx_to_token(idx.item()) for idx in target]\n",
    "                \n",
    "                print(f'\\tInput: {decoded_input}')\n",
    "                print(f'\\tOutput: {output}')\n",
    "                print(f'\\tTarget: {decoded_target}')\n",
    "                break\n",
    "                \n",
    "        torch.cuda.synchronize()\n",
    "        epoch_end_time.record()\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed_epoch_time = round(epoch_start_time.elapsed_time(epoch_end_time) / 60000, 3)\n",
    "        print(f'\\tEpoch elapsed time: {elapsed_epoch_time} minutes')\n",
    "        \n",
    "        if patience == 0:\n",
    "            print(f'\\nModel learning finished due to early stopping')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение функции эксплуатации обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: Seq2SeqModel, sentence: str, max_seq_len=10):\n",
    "    input_tensor = lemm_text_transformer.text_to_tensor(sentence, max_seq_len).to(device)\n",
    "    input_tensor = torch.transpose(input_tensor, 1, 0)\n",
    "    sos_idx = lemm_text_transformer.special_tokens_to_idx.get('<SOS>')\n",
    "    eos_idx = lemm_text_transformer.special_tokens_to_idx.get('<EOS>')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        hidden, cell = model.encoder(input_tensor)\n",
    "        \n",
    "        predicted_indexes = [sos_idx]\n",
    "        \n",
    "#         while True:\n",
    "#             prev_idx = torch.tensor([predicted_indexes[-1]], dtype=torch.long, device=device)\n",
    "            \n",
    "#             output, hidden, cell = model.decoder(prev_idx, hidden, cell)\n",
    "#             output = output.squeeze(0)\n",
    "            \n",
    "#             best_prediction = output.argmax(dim=1).item()\n",
    "            \n",
    "#             if best_prediction == eos_idx:\n",
    "#                 break\n",
    "            \n",
    "#             predicted_indexes.append(best_prediction)\n",
    "                       \n",
    "        \n",
    "        for _ in range(1, max_seq_len):\n",
    "            prev_idx = torch.tensor([predicted_indexes[-1]], dtype=torch.long, device=device)\n",
    "            \n",
    "            output, hidden, cell = model.decoder(prev_idx, hidden, cell)\n",
    "            output = output.squeeze(0)\n",
    "            \n",
    "            best_prediction = output.argmax(dim=1).item()\n",
    "            \n",
    "            if best_prediction == eos_idx:\n",
    "                break\n",
    "                \n",
    "            predicted_indexes.append(best_prediction)\n",
    "        \n",
    "    predicted_tokens = [orig_text_transformer.vocab.idx_to_token(idx) for idx in predicted_indexes]\n",
    "    return predicted_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecb7f34f0474437ad0744a779ac3f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e141359522a94bdaaffb41b34ee82eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 11.00084400177002\n",
      "\tIteration #250: training loss = 4.2196044921875\n",
      "\tIteration #500: training loss = 3.2808210849761963\n",
      "\tIteration #750: training loss = 2.5662546157836914\n",
      "\tIteration #1000: training loss = 2.184664726257324\n",
      "\tIteration #1250: training loss = 1.822027325630188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b81889a020f4b349ced4697415e7cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 1.7900535351988198\n",
      "\tInput: ['<SOS>', 'я', 'всегда', 'ударять', 'по', 'мяч', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['я', 'всегда', 'скучаю', 'по', '<ДАННЫЕ_УДАЛЕНЫ>', '.']\n",
      "\tTarget: ['<SOS>', 'я', 'всегда', 'ударяю', 'по', 'мячу', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 5.984 minutes\n",
      "\n",
      "Epoch [2 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6003029f284675b61bbe458e9c969e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 2.244800090789795\n",
      "\tIteration #250: training loss = 1.7715039253234863\n",
      "\tIteration #500: training loss = 1.6209949254989624\n",
      "\tIteration #750: training loss = 1.2364271879196167\n",
      "\tIteration #1000: training loss = 1.2012498378753662\n",
      "\tIteration #1250: training loss = 1.0096397399902344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f2d97408d6473e90953b63a609df15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 1.0527670988138171\n",
      "\tInput: ['<SOS>', 'девушка', 'зажмуриться', 'от', 'ужас', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['девушка', 'зажмурилась', 'от', 'ужаса', '.']\n",
      "\tTarget: ['<SOS>', 'девушка', 'зажмурилась', 'от', 'ужаса', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.182 minutes\n",
      "\n",
      "Epoch [3 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be208c527f34a2e87a4f02ab151714c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 1.3237749338150024\n",
      "\tIteration #250: training loss = 0.9848141074180603\n",
      "\tIteration #500: training loss = 0.9563255310058594\n",
      "\tIteration #750: training loss = 0.7145868539810181\n",
      "\tIteration #1000: training loss = 0.741412341594696\n",
      "\tIteration #1250: training loss = 0.6275113224983215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe4638139d64de98b704d995c6073e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.7826366234516752\n",
      "\tInput: ['<SOS>', 'я', 'присоединиться', 'к', 'масса', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['я', 'присоединился', 'к', '<ДАННЫЕ_УДАЛЕНЫ>', '.']\n",
      "\tTarget: ['<SOS>', 'я', 'присоединился', 'к', 'массе', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.195 minutes\n",
      "\n",
      "Epoch [4 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65eecc9adfa64d51bc4d2c3692f82a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.8233298063278198\n",
      "\tIteration #250: training loss = 0.5715072154998779\n",
      "\tIteration #500: training loss = 0.6232591867446899\n",
      "\tIteration #750: training loss = 0.4912452697753906\n",
      "\tIteration #1000: training loss = 0.4703558683395386\n",
      "\tIteration #1250: training loss = 0.4086615741252899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffa6ba8a4094c16a3b42959267164cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.665241299332052\n",
      "\tInput: ['<SOS>', 'сашка', 'взять', 'в', 'лиловый', 'оправа', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['сашка', 'взял', 'в', '<ДАННЫЕ_УДАЛЕНЫ>', 'техникуме', '.']\n",
      "\tTarget: ['<SOS>', 'сашка', 'взял', 'в', 'лиловой', '<ДАННЫЕ_УДАЛЕНЫ>', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.191 minutes\n",
      "\n",
      "Epoch [5 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0d5d8724df4abbae347c72134fdfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.5101946592330933\n",
      "\tIteration #250: training loss = 0.3305533826351166\n",
      "\tIteration #500: training loss = 0.4313153326511383\n",
      "\tIteration #750: training loss = 0.326799601316452\n",
      "\tIteration #1000: training loss = 0.3459184169769287\n",
      "\tIteration #1250: training loss = 0.2728794813156128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa086e2955564924b20c7fc5c7bb6bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.6086651566235916\n",
      "\tInput: ['<SOS>', 'капитан', 'повернуться', 'к', 'энн', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['капитан', 'повернулся', 'к', 'энн', '.']\n",
      "\tTarget: ['<SOS>', 'капитан', 'повернулся', 'к', 'энн', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.165 minutes\n",
      "\n",
      "Epoch [6 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660d7e9239c84857a6aa2746a7456721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.33056730031967163\n",
      "\tIteration #250: training loss = 0.20200130343437195\n",
      "\tIteration #500: training loss = 0.2887400686740875\n",
      "\tIteration #750: training loss = 0.247162863612175\n",
      "\tIteration #1000: training loss = 0.23237352073192596\n",
      "\tIteration #1250: training loss = 0.2136102318763733\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bb067a97e44ff4b07c16f52dbd38e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.5787783321263134\n",
      "\tInput: ['<SOS>', 'он', 'искоса', 'поглядеть', 'на', 'гермиона', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['он', 'искоса', 'поглядел', 'на', 'гермиону', '.']\n",
      "\tTarget: ['<SOS>', 'он', 'искоса', 'поглядел', 'на', 'гермиону', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.171 minutes\n",
      "\n",
      "Epoch [7 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59412b4e00d45df9682fe168e64735c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.22271345555782318\n",
      "\tIteration #250: training loss = 0.1454756259918213\n",
      "\tIteration #500: training loss = 0.2203332483768463\n",
      "\tIteration #750: training loss = 0.1709129810333252\n",
      "\tIteration #1000: training loss = 0.20406152307987213\n",
      "\tIteration #1250: training loss = 0.1571664810180664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f2f27c547146b3a3ee3e913db333bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.5687042699343916\n",
      "\tInput: ['<SOS>', 'браун', 'резко', 'повернуться', 'к', 'алексис', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['браун', 'резко', 'повернулся', 'к', '<ДАННЫЕ_УДАЛЕНЫ>', '.']\n",
      "\tTarget: ['<SOS>', 'браун', 'резко', 'повернулся', 'к', '<ДАННЫЕ_УДАЛЕНЫ>', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.18 minutes\n",
      "\n",
      "Epoch [8 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcace7d6be7e4c689bd88eec059da8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.1591860055923462\n",
      "\tIteration #250: training loss = 0.12383783608675003\n",
      "\tIteration #500: training loss = 0.1682780385017395\n",
      "\tIteration #750: training loss = 0.14022408425807953\n",
      "\tIteration #1000: training loss = 0.162378191947937\n",
      "\tIteration #1250: training loss = 0.11923165619373322\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8137db10e44402daf81e823280787d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.557683726583702\n",
      "\tInput: ['<SOS>', 'саманта', 'побежать', 'в', 'лаборатория', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['саманта', 'побежала', 'в', 'лабораторию', '.']\n",
      "\tTarget: ['<SOS>', 'саманта', 'побежала', 'в', 'лабораторию', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.175 minutes\n",
      "\n",
      "Epoch [9 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c995115ff51c4c5fad8c9aa38e225e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.14510950446128845\n",
      "\tIteration #250: training loss = 0.08425789326429367\n",
      "\tIteration #500: training loss = 0.16126611828804016\n",
      "\tIteration #750: training loss = 0.12940996885299683\n",
      "\tIteration #1000: training loss = 0.13750624656677246\n",
      "\tIteration #1250: training loss = 0.10021355748176575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce68949cf3d14a87a391535e24e95f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.555608161981555\n",
      "\tInput: ['<SOS>', 'я', 'медленно', 'идти', 'по', 'городок', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['я', 'медленно', 'шел', 'по', 'городку', '.']\n",
      "\tTarget: ['<SOS>', 'я', 'медленно', 'шел', 'по', 'городку', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.163 minutes\n",
      "\n",
      "Epoch [10 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3797f81e7c2a433eb271c9a77a2551a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.1281607300043106\n",
      "\tIteration #250: training loss = 0.08394954353570938\n",
      "\tIteration #500: training loss = 0.12871237099170685\n",
      "\tIteration #750: training loss = 0.10635174065828323\n",
      "\tIteration #1000: training loss = 0.1069166287779808\n",
      "\tIteration #1250: training loss = 0.10388542711734772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e113e3b0c4e94ab5b82a94e7cd68857d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.5538733795933102\n",
      "\tInput: ['<SOS>', 'он', 'повернуться', 'в', 'седло', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['он', 'повернулся', 'в', 'седле', '.']\n",
      "\tTarget: ['<SOS>', 'он', 'повернулся', 'в', 'седле', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.174 minutes\n",
      "\n",
      "Epoch [11 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c765aac71242e7bfef51659d829c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.0969495102763176\n",
      "\tIteration #250: training loss = 0.06817984580993652\n",
      "\tIteration #500: training loss = 0.0891454815864563\n",
      "\tIteration #750: training loss = 0.09971724450588226\n",
      "\tIteration #1000: training loss = 0.10060471296310425\n",
      "\tIteration #1250: training loss = 0.09673718363046646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38df6eccb8204f718eb46524376dcc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.5534522308819536\n",
      "\tInput: ['<SOS>', 'он', 'смотреть', 'в', 'темнота', ';', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['он', 'смотрел', 'в', 'темноту', ';']\n",
      "\tTarget: ['<SOS>', 'он', 'смотрел', 'в', 'темноту', ';', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.136 minutes\n",
      "\n",
      "Epoch [12 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1980e985e740c997c94c7d3dc0fcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.10112450271844864\n",
      "\tIteration #250: training loss = 0.060384444892406464\n",
      "\tIteration #500: training loss = 0.0989241972565651\n",
      "\tIteration #750: training loss = 0.09463158249855042\n",
      "\tIteration #1000: training loss = 0.09263592213392258\n",
      "\tIteration #1250: training loss = 0.09083976596593857\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8829533981ce497a80a724952f31dadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.5520763064640156\n",
      "\tInput: ['<SOS>', 'виктор', 'решиться', 'на', 'крайний', 'средство', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['виктор', 'решился', 'на', 'крайнее', 'средство', '.']\n",
      "\tTarget: ['<SOS>', 'виктор', 'решился', 'на', 'крайнее', 'средство', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 6.17 minutes\n",
      "\n",
      "Epoch [13 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2b836a9c2642228f4ca6b070a7da70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.08408451080322266\n",
      "\tIteration #250: training loss = 0.058484990149736404\n",
      "\tIteration #500: training loss = 0.10459940135478973\n",
      "\tIteration #750: training loss = 0.08478805422782898\n",
      "\tIteration #1000: training loss = 0.09069288522005081\n",
      "\tIteration #1250: training loss = 0.08381370455026627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a658b4fb61f547f585c355103b3ac333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.5527546777241472\n",
      "\tInput: ['<SOS>', 'он', 'взглянуть', 'на', 'нож', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['он', 'взглянул', 'на', 'нож', '.']\n",
      "\tTarget: ['<SOS>', 'он', 'взглянул', 'на', 'нож', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 5.876 minutes\n",
      "\n",
      "Epoch [14 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50073df6f1e64f17bb52f46342e59d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.07135278731584549\n",
      "\tIteration #250: training loss = 0.04725491255521774\n",
      "\tIteration #500: training loss = 0.08378446102142334\n",
      "\tIteration #750: training loss = 0.07651790976524353\n",
      "\tIteration #1000: training loss = 0.07493138313293457\n",
      "\tIteration #1250: training loss = 0.07616628706455231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1ebcd585e74399b4270d26b9027e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.5558792408825695\n",
      "\tInput: ['<SOS>', 'они', 'двигаться', 'вслед', 'за', 'лодка', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['они', 'двигались', 'вслед', 'за', 'лодкой', '.']\n",
      "\tTarget: ['<SOS>', 'они', 'двигались', 'вслед', 'за', 'лодкой', '.', '<EOS>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 5.873 minutes\n",
      "\n",
      "Epoch [15 / 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f03bbbae8064736af5ac2dc814d394b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch training iterations:   0%|          | 0/1254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIteration #0: training loss = 0.07581671327352524\n",
      "\tIteration #250: training loss = 0.04735279455780983\n",
      "\tIteration #500: training loss = 0.08201677352190018\n",
      "\tIteration #750: training loss = 0.07472237199544907\n",
      "\tIteration #1000: training loss = 0.07938290387392044\n",
      "\tIteration #1250: training loss = 0.05841830000281334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2e4155d76b47d383250cc94ea2ea02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch validating iterations:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation loss = 0.5610537719035494\n",
      "\tInput: ['<SOS>', 'саша', 'отойти', 'в', 'сторона', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tOutput: ['саша', 'отошла', 'в', 'сторону', '.']\n",
      "\tTarget: ['<SOS>', 'саша', 'отошел', 'в', 'сторону', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\tEpoch elapsed time: 5.871 minutes\n",
      "\n",
      "Model learning finished due to early stopping\n"
     ]
    }
   ],
   "source": [
    "# train(model, optimizer, criterion, train_loader, val_loader, test_loader, epochs_amount, max_norm, patience, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model(model, optimizer, criterion, model_path + model_name)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# del model\n",
    "# del optimizer\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sample = train_df.sample(100)\n",
    "# test_input = test_sample.lemm_texts.to_list()\n",
    "# test_target = test_sample.orig_texts.to_list()\n",
    "# test_pair = list(zip(test_input, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: он нуждаться в дракон.\n",
      "Output: ['он', 'нуждался', 'в', 'драконе', '.']\n",
      "Target: он нуждался в драконе.\n",
      "\n",
      "\n",
      "Input: я вспотеть от один мысль.\n",
      "Output: ['я', 'вспотел', 'от', 'одной', 'мысли', '.']\n",
      "Target: я вспотел от одной мысли.\n",
      "\n",
      "\n",
      "Input: мы стоить на место!\n",
      "Output: ['мы', 'стоим', 'на', 'месте', '!']\n",
      "Target: мы стоим на месте!\n",
      "\n",
      "\n",
      "Input: она идти вдоль берег.\n",
      "Output: ['она', 'шла', 'вдоль', 'берега', '.']\n",
      "Target: она шла вдоль берега.\n",
      "\n",
      "\n",
      "Input: он выйти из убежище.\n",
      "Output: ['он', 'вышел', 'из', 'убежища', '.']\n",
      "Target: он вышел из убежища.\n",
      "\n",
      "\n",
      "Input: она заворачиваться в сторона.\n",
      "Output: ['она', '<ДАННЫЕ_УДАЛЕНЫ>', 'в', 'сторону', '.']\n",
      "Target: она заворачивалась в сторону.\n",
      "\n",
      "\n",
      "Input: они никогда не появляться в школа.\n",
      "Output: ['они', 'никогда', 'не', 'появлялись', 'в', 'школе', '.']\n",
      "Target: они никогда не появлялись в школе.\n",
      "\n",
      "\n",
      "Input: разведчик растаять в небо.\n",
      "Output: ['разведчик', 'растаял', 'в', 'небе', '.']\n",
      "Target: разведчик растаял в небе.\n",
      "\n",
      "\n",
      "Input: мы работать с копия.\n",
      "Output: ['мы', 'работали', 'с', '<ДАННЫЕ_УДАЛЕНЫ>', '.']\n",
      "Target: мы работали с копией.\n",
      "\n",
      "\n",
      "Input: они приближаться к лифт.\n",
      "Output: ['они', 'приближались', 'к', 'лифту', '.']\n",
      "Target: они приближаются к лифту.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for input_sentence, target_sentence in test_pair[:10]:\n",
    "#     model_output = evaluate(model, input_sentence)\n",
    "#     print(f'Input: {input_sentence}')\n",
    "#     print(f'Output: {model_output}')\n",
    "#     print(f'Target: {target_sentence}')\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
