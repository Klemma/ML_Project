{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Импорт необходимых зависимостей"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install navec"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:19:41.780127Z",
     "iopub.execute_input": "2021-06-04T15:19:41.780503Z",
     "iopub.status.idle": "2021-06-04T15:19:49.620470Z",
     "shell.execute_reply.started": "2021-06-04T15:19:41.780423Z",
     "shell.execute_reply": "2021-06-04T15:19:49.619534Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting navec\n  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from navec) (1.19.5)\nInstalling collected packages: navec\nSuccessfully installed navec-0.10.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from random import random, sample\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from functools import reduce\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchtext.data.metrics import bleu_score\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:19:49.623821Z",
     "iopub.execute_input": "2021-06-04T15:19:49.624076Z",
     "iopub.status.idle": "2021-06-04T15:19:52.083108Z",
     "shell.execute_reply.started": "2021-06-04T15:19:49.624048Z",
     "shell.execute_reply": "2021-06-04T15:19:52.082255Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 1"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:19:53.746877Z",
     "iopub.execute_input": "2021-06-04T15:19:53.747237Z",
     "iopub.status.idle": "2021-06-04T15:19:53.752226Z",
     "shell.execute_reply.started": "2021-06-04T15:19:53.747207Z",
     "shell.execute_reply": "2021-06-04T15:19:53.750802Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка данных"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/lenta/dataset.csv')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:19:57.332409Z",
     "iopub.execute_input": "2021-06-04T15:19:57.332800Z",
     "iopub.status.idle": "2021-06-04T15:20:15.679376Z",
     "shell.execute_reply.started": "2021-06-04T15:19:57.332767Z",
     "shell.execute_reply": "2021-06-04T15:20:15.678286Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = df.sample(frac=0.5, random_state=RANDOM_STATE)\n",
    "df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:15.684013Z",
     "iopub.execute_input": "2021-06-04T15:20:15.684374Z",
     "iopub.status.idle": "2021-06-04T15:20:16.561357Z",
     "shell.execute_reply.started": "2021-06-04T15:20:15.684338Z",
     "shell.execute_reply": "2021-06-04T15:20:16.560572Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "execution_count": 5,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                orig_texts  \\\n1245806  об этом сообщает риа новости со ссылкой на мат...   \n1594042  генеральный прокурор рф владимир устинов счита...   \n705659   телеканал «дождь» восстановил вещание, прерван...   \n603796   соответствующее требование прозвучало во время...   \n1430273  в пятницу вечером на сайтах \"единой россии\", \"...   \n...                                                    ...   \n1331395  об этом заявил президент - председатель правле...   \n1710395  \"мы думаем, что они (страны-члены совбеза) пре...   \n1434398  социологи \"росгосстраха\" оценили сознательност...   \n1832873  российская сборная сохранила за собой 24 строчку.   \n1537488  эксперты компании связывают это с прекращением...   \n\n                                                lemm_texts       nsubj  \\\n1245806  о это сообщать риа новость с ссылка на мать по...         риа   \n1594042  генеральный прокурор рф владимир устинов счита...    прокурор   \n705659   телеканал « дождь » восстановить вещание, прер...   телеканал   \n603796   соответствующий требование прозвучать в время ...  требование   \n1430273  в пятница вечером на сайт \"единый россия\", \"гр...   заявления   \n...                                                    ...         ...   \n1331395  о это заявить президент - председатель правлен...   президент   \n1710395  \\\" мы думать, что они (страна-член совбез) пре...          мы   \n1434398  социолог \"росгосстрах\"оценить сознательность р...   социологи   \n1832873   российский сборная сохранить за себя 24 строчка.     сборная   \n1537488  эксперт компания связывать это с прекращение и...    эксперты   \n\n            gender tense  \n1245806       neut  pres  \n1594042       masc  pres  \n705659        masc  past  \n603796        neut  past  \n1430273       neut  past  \n...            ...   ...  \n1331395       masc  past  \n1710395  undefined  pres  \n1434398       masc  past  \n1832873        fem  past  \n1537488       masc  pres  \n\n[926362 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>orig_texts</th>\n      <th>lemm_texts</th>\n      <th>nsubj</th>\n      <th>gender</th>\n      <th>tense</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1245806</th>\n      <td>об этом сообщает риа новости со ссылкой на мат...</td>\n      <td>о это сообщать риа новость с ссылка на мать по...</td>\n      <td>риа</td>\n      <td>neut</td>\n      <td>pres</td>\n    </tr>\n    <tr>\n      <th>1594042</th>\n      <td>генеральный прокурор рф владимир устинов счита...</td>\n      <td>генеральный прокурор рф владимир устинов счита...</td>\n      <td>прокурор</td>\n      <td>masc</td>\n      <td>pres</td>\n    </tr>\n    <tr>\n      <th>705659</th>\n      <td>телеканал «дождь» восстановил вещание, прерван...</td>\n      <td>телеканал « дождь » восстановить вещание, прер...</td>\n      <td>телеканал</td>\n      <td>masc</td>\n      <td>past</td>\n    </tr>\n    <tr>\n      <th>603796</th>\n      <td>соответствующее требование прозвучало во время...</td>\n      <td>соответствующий требование прозвучать в время ...</td>\n      <td>требование</td>\n      <td>neut</td>\n      <td>past</td>\n    </tr>\n    <tr>\n      <th>1430273</th>\n      <td>в пятницу вечером на сайтах \"единой россии\", \"...</td>\n      <td>в пятница вечером на сайт \"единый россия\", \"гр...</td>\n      <td>заявления</td>\n      <td>neut</td>\n      <td>past</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1331395</th>\n      <td>об этом заявил президент - председатель правле...</td>\n      <td>о это заявить президент - председатель правлен...</td>\n      <td>президент</td>\n      <td>masc</td>\n      <td>past</td>\n    </tr>\n    <tr>\n      <th>1710395</th>\n      <td>\"мы думаем, что они (страны-члены совбеза) пре...</td>\n      <td>\\\" мы думать, что они (страна-член совбез) пре...</td>\n      <td>мы</td>\n      <td>undefined</td>\n      <td>pres</td>\n    </tr>\n    <tr>\n      <th>1434398</th>\n      <td>социологи \"росгосстраха\" оценили сознательност...</td>\n      <td>социолог \"росгосстрах\"оценить сознательность р...</td>\n      <td>социологи</td>\n      <td>masc</td>\n      <td>past</td>\n    </tr>\n    <tr>\n      <th>1832873</th>\n      <td>российская сборная сохранила за собой 24 строчку.</td>\n      <td>российский сборная сохранить за себя 24 строчка.</td>\n      <td>сборная</td>\n      <td>fem</td>\n      <td>past</td>\n    </tr>\n    <tr>\n      <th>1537488</th>\n      <td>эксперты компании связывают это с прекращением...</td>\n      <td>эксперт компания связывать это с прекращение и...</td>\n      <td>эксперты</td>\n      <td>masc</td>\n      <td>pres</td>\n    </tr>\n  </tbody>\n</table>\n<p>926362 rows × 5 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Определение классов словаря и трансформера текста"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens: List[str], unk_idx: int):\n",
    "        self._tokens = tokens\n",
    "        self._token_to_idx = {token: idx for idx, token in enumerate(tqdm(tokens, 'Transforming tokens'))}\n",
    "        self._unk_idx = unk_idx\n",
    "        \n",
    "    def token_to_idx(self, token: str) -> int:\n",
    "        return self._token_to_idx.get(token, self._unk_idx)\n",
    "    \n",
    "    def idx_to_token(self, idx: int) -> str:\n",
    "        return self._tokens[idx]\n",
    "    \n",
    "    def save_vocab(self, path='./vocab.vcb'):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self, f)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:33.877719Z",
     "iopub.execute_input": "2021-06-04T15:20:33.878043Z",
     "iopub.status.idle": "2021-06-04T15:20:33.884575Z",
     "shell.execute_reply.started": "2021-06-04T15:20:33.878010Z",
     "shell.execute_reply": "2021-06-04T15:20:33.883298Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class TextTransformer:\n    def __init__(self, vocab_size: int = 250000):\n        self.vocab = None\n        self.vocab_size = vocab_size\n        self.special_tokens_to_idx = {'<unk>': 0, '<pad>': 1, '<sos>': 2, '<eos>': 3}\n#         self.special_tokens_to_idx = None\n        self._tokenizer = nltk.tokenize.word_tokenize\n    \n    def tokenize(self, text, language='russian') -> List[str]:\n        return self._tokenizer(text.lower(), language)\n    \n    def build_vocab(self, tokens: List[str], unk_idx: int = 0, pad_idx: int = 1):\n#         self.special_tokens_to_idx = {'<unk>': unk_idx, '<pad>': pad_idx, '<sos>': unk_idx + 1, '<eos>': unk_idx + 2}\n#         tokens.extend(list(self.special_tokens_to_idx.keys()))\n#         self.vocab = Vocab(tokens, unk_idx)\n        tokens_ = [special_token for special_token in self.special_tokens_to_idx.keys()]\n        special_tokens_amount = len(self.special_tokens_to_idx)\n        \n        for token, _ in Counter(tokens).most_common(self.vocab_size - special_tokens_amount):\n            tokens_.append(token)\n        \n        unk_idx = self.special_tokens_to_idx.get('<unk>')\n        self.vocab = Vocab(tokens_, unk_idx)\n        \n    def transform_text(self, text: str) -> List[int]:\n        tokenized_text = self.tokenize(text)\n        transformed = [self.vocab.token_to_idx(token) for token in tokenized_text]\n        return transformed\n    \n    def fit(self, texts: List[str]) -> None:\n        transformed_texts = []\n        \n        tokenized_texts = [self.tokenize(text) for text in tqdm(texts, 'Tokenizing texts')]\n        tokens = chain(*tokenized_texts)\n        self.build_vocab(tokens)\n        \n#         for tokenized_text in tqdm(tokenized_texts, 'Transforming texts'):\n#             transformed = [self.vocab.token_to_idx(token) for token in tokenized_text]\n#             transformed_texts.append(transformed)\n    \n    def transform_texts(self, texts: List[str]) -> List[List[int]]:\n        transformed_texts = [transform_text(text) for text in tqdm(texts, 'Transforming texts')]\n        return transformed_texts\n    \n    def text_to_tensor(self, text: str, max_seq_len) -> torch.tensor:\n        transformed_text = self.transform_text(text)\n        pad_idx = self.special_tokens_to_idx.get('<pad>')\n        sos_idx = self.special_tokens_to_idx.get('<sos>')\n        eos_idx = self.special_tokens_to_idx.get('<eos>')\n        \n        pad_size = 0\n        if len(transformed_text) >= max_seq_len:\n            transformed_text = transformed_text[:max_seq_len]\n        else:\n            pad_size = max_seq_len - len(transformed_text)\n            transformed_text.extend([pad_idx] * pad_size)   \n        transformed_text.insert(0, sos_idx)\n        transformed_text.insert(len(transformed_text) - pad_size, eos_idx)\n        \n        tensor = torch.tensor(transformed_text, dtype=torch.long)\n        return tensor.unsqueeze(0)\n    \n    def texts_to_tensor(self, texts: List[str], max_seq_len) -> torch.tensor:\n        pad_idx = self.special_tokens_to_idx.get('<pad>')\n        sos_idx = self.special_tokens_to_idx.get('<sos>')\n        eos_idx = self.special_tokens_to_idx.get('<eos>')\n        transformed_texts = []\n        \n        for text in tqdm(texts, 'Building tensor'):\n            transformed_text = self.transform_text(text)\n            pad_size = 0\n            if len(transformed_text) >= max_seq_len:\n                transformed_text = transformed_text[:max_seq_len]\n            else:\n                pad_size = max_seq_len - len(transformed_text)\n                transformed_text.extend([pad_idx] * pad_size)   \n            transformed_text.insert(0, sos_idx)\n            transformed_text.insert(len(transformed_text) - pad_size, eos_idx)\n            transformed_texts.append(transformed_text)\n        \n        tensor = torch.tensor(transformed_texts, dtype=torch.long).permute(1, 0)\n        return tensor",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:34.084154Z",
     "iopub.execute_input": "2021-06-04T15:20:34.084421Z",
     "iopub.status.idle": "2021-06-04T15:20:34.101360Z",
     "shell.execute_reply.started": "2021-06-04T15:20:34.084396Z",
     "shell.execute_reply": "2021-06-04T15:20:34.100379Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Разбиение данных на обучающую, тестовую и валидационную выборки",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_df, test_df = model_selection.train_test_split(df, test_size=0.1, random_state=RANDOM_STATE)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:35.599651Z",
     "iopub.execute_input": "2021-06-04T15:20:35.599976Z",
     "iopub.status.idle": "2021-06-04T15:20:36.078851Z",
     "shell.execute_reply.started": "2021-06-04T15:20:35.599947Z",
     "shell.execute_reply": "2021-06-04T15:20:36.077972Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "test_df, val_df = model_selection.train_test_split(test_df, test_size=0.5, random_state=RANDOM_STATE)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:36.080273Z",
     "iopub.execute_input": "2021-06-04T15:20:36.080639Z",
     "iopub.status.idle": "2021-06-04T15:20:36.109529Z",
     "shell.execute_reply.started": "2021-06-04T15:20:36.080600Z",
     "shell.execute_reply": "2021-06-04T15:20:36.108738Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Токенизация текстов и индексация токенов",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "vocab_size = 125000",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:37.725743Z",
     "iopub.execute_input": "2021-06-04T15:20:37.726065Z",
     "iopub.status.idle": "2021-06-04T15:20:37.730657Z",
     "shell.execute_reply.started": "2021-06-04T15:20:37.726035Z",
     "shell.execute_reply": "2021-06-04T15:20:37.728893Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "max_seq_len = 40",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:37.892959Z",
     "iopub.execute_input": "2021-06-04T15:20:37.893204Z",
     "iopub.status.idle": "2021-06-04T15:20:37.897345Z",
     "shell.execute_reply.started": "2021-06-04T15:20:37.893179Z",
     "shell.execute_reply": "2021-06-04T15:20:37.896511Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "text_transformer = TextTransformer(vocab_size)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:38.987703Z",
     "iopub.execute_input": "2021-06-04T15:20:38.988019Z",
     "iopub.status.idle": "2021-06-04T15:20:38.992304Z",
     "shell.execute_reply.started": "2021-06-04T15:20:38.987990Z",
     "shell.execute_reply": "2021-06-04T15:20:38.991288Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# text_transformer.build_vocab(embedding.vocab.words[0:-2], embedding.vocab.unk_id, embedding.vocab.pad_id)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# lemm_vocab_size = 23000\n# orig_vocab_size = 65000",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# lemm_text_transformer = TextTransformer(lemm_vocab_size)\n# orig_text_transformer = TextTransformer(orig_vocab_size)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "text_transformer.fit(train_df.orig_texts.to_list() + train_df.lemm_texts.to_list())",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T14:44:46.922842Z",
     "iopub.execute_input": "2021-06-04T14:44:46.923175Z",
     "iopub.status.idle": "2021-06-04T14:52:18.097778Z",
     "shell.execute_reply.started": "2021-06-04T14:44:46.923142Z",
     "shell.execute_reply": "2021-06-04T14:52:18.096702Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Tokenizing texts:   0%|          | 0/1667450 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d278b0d335d14ff481f75ddcb71c8d7e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming tokens:   0%|          | 0/125000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f600fa7a34c44a6388598b22e9f25a99"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# with open('../input/cached-data/tokens.list', 'rb') as f:\n#     tokens = pickle.load(f)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:43.567431Z",
     "iopub.execute_input": "2021-06-04T15:20:43.567779Z",
     "iopub.status.idle": "2021-06-04T15:20:43.637105Z",
     "shell.execute_reply.started": "2021-06-04T15:20:43.567747Z",
     "shell.execute_reply": "2021-06-04T15:20:43.636267Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# text_transformer.build_vocab(tokens)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:20:47.833624Z",
     "iopub.execute_input": "2021-06-04T15:20:47.833952Z",
     "iopub.status.idle": "2021-06-04T15:20:48.024609Z",
     "shell.execute_reply.started": "2021-06-04T15:20:47.833924Z",
     "shell.execute_reply": "2021-06-04T15:20:48.023635Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming tokens:   0%|          | 0/124999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94e29f6806524ae39fc08eb34d7aaee3"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# tokens = [text_transformer.vocab.idx_to_token(idx) for idx in range(4, 124999)]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:10:50.166068Z",
     "iopub.execute_input": "2021-06-04T15:10:50.166507Z",
     "iopub.status.idle": "2021-06-04T15:10:50.245493Z",
     "shell.execute_reply.started": "2021-06-04T15:10:50.166468Z",
     "shell.execute_reply": "2021-06-04T15:10:50.244508Z"
    },
    "trusted": true
   },
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# with open('./tokens.list', 'wb') as f:\n#     pickle.dump(tokens, f)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:10:51.731134Z",
     "iopub.execute_input": "2021-06-04T15:10:51.731501Z",
     "iopub.status.idle": "2021-06-04T15:10:51.785580Z",
     "shell.execute_reply.started": "2021-06-04T15:10:51.731470Z",
     "shell.execute_reply": "2021-06-04T15:10:51.784699Z"
    },
    "trusted": true
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# orig_text_transformer.fit(train_df.orig_texts)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Перевод данных в тензоры",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# tensors = {\n#     'train_lemm_tensor': train_lemm_tensor,\n#     'test_lemm_tensor': test_lemm_tensor,\n#     'val_lemm_tensor': val_lemm_tensor,\n#     'train_orig_tensor': train_orig_tensor,\n#     'test_orig_tensor': test_orig_tensor,\n#     'val_orig_tensor': val_orig_tensor\n# }\n\n# with open('./data_tensors.data', 'wb') as f:\n#     pickle.dump(tensors, f)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:08:01.290629Z",
     "iopub.execute_input": "2021-06-04T15:08:01.290951Z",
     "iopub.status.idle": "2021-06-04T15:08:02.174897Z",
     "shell.execute_reply.started": "2021-06-04T15:08:01.290921Z",
     "shell.execute_reply": "2021-06-04T15:08:02.174048Z"
    },
    "trusted": true
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# with open('../input/cached-data/data_tensors.data', 'rb') as f:\n#     tensors = pickle.load(f)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:21.788575Z",
     "iopub.execute_input": "2021-06-04T15:21:21.788909Z",
     "iopub.status.idle": "2021-06-04T15:21:26.539956Z",
     "shell.execute_reply.started": "2021-06-04T15:21:21.788879Z",
     "shell.execute_reply": "2021-06-04T15:21:26.539092Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# train_lemm_tensor, test_lemm_tensor, val_lemm_tensor,\\\n# train_orig_tensor, test_orig_tensor, val_orig_tensor = tensors.values()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:26.541271Z",
     "iopub.execute_input": "2021-06-04T15:21:26.541617Z",
     "iopub.status.idle": "2021-06-04T15:21:26.544943Z",
     "shell.execute_reply.started": "2021-06-04T15:21:26.541580Z",
     "shell.execute_reply": "2021-06-04T15:21:26.544168Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_lemm_tensor = text_transformer.texts_to_tensor(train_df.lemm_texts.to_list(), max_seq_len)\ntest_lemm_tensor = text_transformer.texts_to_tensor(test_df.lemm_texts.to_list(), max_seq_len)\nval_lemm_tensor = text_transformer.texts_to_tensor(val_df.lemm_texts.to_list(), max_seq_len)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T14:52:18.099408Z",
     "iopub.execute_input": "2021-06-04T14:52:18.099776Z",
     "iopub.status.idle": "2021-06-04T14:56:33.175927Z",
     "shell.execute_reply.started": "2021-06-04T14:52:18.099724Z",
     "shell.execute_reply": "2021-06-04T14:56:33.174863Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Building tensor:   0%|          | 0/833725 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "859429a127ac4f779c4b58af3dad0b7d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Building tensor:   0%|          | 0/46318 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34517696961742b1b11f6d7ceafc95f8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Building tensor:   0%|          | 0/46319 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f6e42d8964f4ef6a6ea9e0328b8a359"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "train_orig_tensor = text_transformer.texts_to_tensor(train_df.orig_texts.to_list(), max_seq_len)\ntest_orig_tensor = text_transformer.texts_to_tensor(test_df.orig_texts.to_list(), max_seq_len)\nval_orig_tensor = text_transformer.texts_to_tensor(val_df.orig_texts.to_list(), max_seq_len)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T14:56:33.177972Z",
     "iopub.execute_input": "2021-06-04T14:56:33.178350Z",
     "iopub.status.idle": "2021-06-04T15:00:54.140536Z",
     "shell.execute_reply.started": "2021-06-04T14:56:33.178310Z",
     "shell.execute_reply": "2021-06-04T15:00:54.139509Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Building tensor:   0%|          | 0/833725 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60acdf48b3054c328a970115c99ded2f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Building tensor:   0%|          | 0/46318 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46a4aabffe744bb59952ab91f8442765"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Building tensor:   0%|          | 0/46319 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddb6c45ad7c44b43852aaaa98fba5ca6"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "gender_to_vec = {\n    'masc': [1, 0, 0, 0],\n    'fem': [0, 1, 0, 0],\n    'neut': [0, 0, 1, 0],\n    'undefined': [0, 0, 0, 1]\n}",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:30.382813Z",
     "iopub.execute_input": "2021-06-04T15:21:30.383134Z",
     "iopub.status.idle": "2021-06-04T15:21:30.387297Z",
     "shell.execute_reply.started": "2021-06-04T15:21:30.383104Z",
     "shell.execute_reply": "2021-06-04T15:21:30.386434Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "tense_to_vec = {\n    'pres': [1, 0, 0],\n    'past': [0, 1, 0],\n    'fut': [0, 0, 1]\n}",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:30.596978Z",
     "iopub.execute_input": "2021-06-04T15:21:30.597236Z",
     "iopub.status.idle": "2021-06-04T15:21:30.601322Z",
     "shell.execute_reply.started": "2021-06-04T15:21:30.597211Z",
     "shell.execute_reply": "2021-06-04T15:21:30.600199Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def transform_context(df, df_type: str):\n    transformed_gender = [gender_to_vec.get(gender) for gender in tqdm(df.gender, f'Transforming gender ({df_type})')]\n    transformed_tense = [tense_to_vec.get(tense) for tense in tqdm(df.tense, f'Transforming tense ({df_type})')]\n    transformed_nsubj = [text_transformer.vocab.token_to_idx(nsubj) for nsubj in tqdm(df.nsubj, f'Transforming nsubj ({df_type})')]\n    \n    context = [transformed_nsubj, transformed_gender, transformed_tense]\n    return context",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:31.887733Z",
     "iopub.execute_input": "2021-06-04T15:21:31.888071Z",
     "iopub.status.idle": "2021-06-04T15:21:31.893727Z",
     "shell.execute_reply.started": "2021-06-04T15:21:31.888042Z",
     "shell.execute_reply": "2021-06-04T15:21:31.892775Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def context_to_tensors(context):\n    nsubj, gender, tense = context\n    \n    nsubj_tensor = torch.tensor(nsubj)\n    gender_tensor = torch.tensor(gender, dtype=torch.float32)\n    tense_tensor = torch.tensor(tense, dtype=torch.float32)\n    \n    context_tensors = [nsubj_tensor, gender_tensor, tense_tensor]\n    return context_tensors",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:32.074363Z",
     "iopub.execute_input": "2021-06-04T15:21:32.074687Z",
     "iopub.status.idle": "2021-06-04T15:21:32.081107Z",
     "shell.execute_reply.started": "2021-06-04T15:21:32.074654Z",
     "shell.execute_reply": "2021-06-04T15:21:32.080256Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_context = transform_context(train_df, 'train')\ntest_context = transform_context(test_df, 'test')\nval_context = transform_context(val_df, 'validation')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:32.288016Z",
     "iopub.execute_input": "2021-06-04T15:21:32.288337Z",
     "iopub.status.idle": "2021-06-04T15:21:34.921278Z",
     "shell.execute_reply.started": "2021-06-04T15:21:32.288306Z",
     "shell.execute_reply": "2021-06-04T15:21:34.920284Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming gender (train):   0%|          | 0/833725 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77cc905be7f246dd840cf4d5084a2bd7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming tense (train):   0%|          | 0/833725 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e42ebe4feae430687a7bf10cd92d4a9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming nsubj (train):   0%|          | 0/833725 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcf5922a94614424ab2a6c00fc0ea041"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming gender (test):   0%|          | 0/46318 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a151579b81474eaeb1211e2ff90c9a79"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming tense (test):   0%|          | 0/46318 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c76e45f467d45499532a6cac5ea81ce"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming nsubj (test):   0%|          | 0/46318 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aef238a9b60742988187e9e5016242b7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming gender (validation):   0%|          | 0/46319 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85098bc7c2f74d239567f7633066a4f7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming tense (validation):   0%|          | 0/46319 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d85c191dd7c2495588dea8c706b02de0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Transforming nsubj (validation):   0%|          | 0/46319 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ef065f93d9045858b6d70a065116e5c"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "train_context_tensors = context_to_tensors(train_context)\ntest_context_tensors = context_to_tensors(test_context)\nval_context_tensors = context_to_tensors(val_context)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:34.922874Z",
     "iopub.execute_input": "2021-06-04T15:21:34.923271Z",
     "iopub.status.idle": "2021-06-04T15:21:35.295317Z",
     "shell.execute_reply.started": "2021-06-04T15:21:34.923204Z",
     "shell.execute_reply": "2021-06-04T15:21:35.294491Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def cut_to_fit_batch(tensor: torch.Tensor, batch_size: int):\n    n_samples = tensor.shape[1]\n    new_n_samples = (n_samples // batch_size) * batch_size\n    result = tensor.split(new_n_samples, dim=1)[0]\n    return torch.transpose(result, 1, 0)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:36.937457Z",
     "iopub.execute_input": "2021-06-04T15:21:36.937788Z",
     "iopub.status.idle": "2021-06-04T15:21:36.942218Z",
     "shell.execute_reply.started": "2021-06-04T15:21:36.937757Z",
     "shell.execute_reply": "2021-06-04T15:21:36.941384Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Построение модели",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class ContextMem(nn.Module):\n    def __init__(self, gender_input_size, tense_input_size, hidden_size, output_size, nsubj_embedding_size, device):\n        super(ContextMem, self).__init__()\n        \n        self.device = device\n\n        self.gender_proj = nn.Linear(gender_input_size, hidden_size, bias=False)\n        self.tense_proj = nn.Linear(tense_input_size, hidden_size, bias=False)\n        self.fc_out = nn.Linear(hidden_size * 2 + nsubj_embedding_size, output_size, bias=False)\n        \n    def forward(self, nsubj_embedding, gender, tense):\n        # nsubj_embedding_shape: (batch_size, embedding_size)\n        # gender_shape: (batch_size, input_size)\n        # tense_shape: (batch_size, input_size)\n        \n        gender = self.gender_proj(gender)\n        # gender_shape: (batch_size, hidden_size)\n        \n        tense = self.tense_proj(tense)\n        # tense_shape: (batch_size, hidden_size)    \n        \n        context = torch.cat([nsubj_embedding, gender, tense], dim=1)\n        # context_shape: (batch_size, hidden_size * 2 + embedding_size) \n        \n        context = self.fc_out(context)\n        # context_shape: (batch_size, output_size)\n        \n        return context",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:38.485738Z",
     "iopub.execute_input": "2021-06-04T15:21:38.486065Z",
     "iopub.status.idle": "2021-06-04T15:21:38.492613Z",
     "shell.execute_reply.started": "2021-06-04T15:21:38.486035Z",
     "shell.execute_reply": "2021-06-04T15:21:38.491748Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class EncoderRNN(nn.Module):\n    def __init__(self, vocab_size: int, embedding_size: int, hidden_size: int, pad_idx: int,\n                 device, num_layers, dropout_p: float, embedding=None, pretrained_embedding_loaded=False):\n        super(EncoderRNN, self).__init__()\n        \n        self.device = device\n        self.num_layers = num_layers\n        \n        self.hidden_size = hidden_size\n        \n        self.embedding = embedding\n        self.pretrained_embedding_loaded = pretrained_embedding_loaded\n        \n        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=0.0, bidirectional=True)\n        self.fc_compressor_hidden = nn.Linear(hidden_size * 2, hidden_size)\n        self.fc_compressor_cell = nn.Linear(hidden_size * 2, hidden_size)\n        \n    def forward(self, x, hidden, cell):\n        # x_shape: (seq_len, batch_size)\n        if self.pretrained_embedding_loaded:\n            with torch.no_grad():\n                embedding = self.embedding(x)\n        else:\n            embedding = self.embedding(x)\n        # embedding_shape: (seq_len, batch_size, embedding_size)\n        encoder_states, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n        # encoder_states: (seq_len, batch_size, hidden_size * 2)\n        # hidden_shape: (num_layers=1 * 2, batch_size, hidden_size)\n        # cell_shape: (num_layers=1 * 2, batch_size, hidden_size)\n        \n        bi_hidden = torch.cat((hidden[0], hidden[1]), dim=1).unsqueeze(0).permute(1, 0, 2)\n        bi_cell = torch.cat((cell[0], cell[1]), dim=1).unsqueeze(0).permute(1, 0, 2)\n        # bi_hidden, bi_cell shapes: (batch_size, 1, hidden_size * 2)\n        \n        hidden_compressed = self.fc_compressor_hidden(bi_hidden).permute(1, 0, 2)\n        cell_compressed = self.fc_compressor_hidden(bi_cell).permute(1, 0, 2)\n        # hidden_compressed, cell_compressed shapes: (1, batch_size, hidden_size)\n        \n        return encoder_states, hidden_compressed, cell_compressed\n    \n    def init_hidden_state(self, batch_size: int):\n        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n        return hidden, cell",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:38.879279Z",
     "iopub.execute_input": "2021-06-04T15:21:38.879581Z",
     "iopub.status.idle": "2021-06-04T15:21:38.891786Z",
     "shell.execute_reply.started": "2021-06-04T15:21:38.879517Z",
     "shell.execute_reply": "2021-06-04T15:21:38.890840Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class DecoderRNN(nn.Module):\n    def __init__(self, vocab_size: int, embedding_size: int, hidden_size: int, output_size: int, pad_idx: int,\n                 device, num_layers, dropout_p: float, embedding=None, pretrained_embedding_loaded=False):\n        super(DecoderRNN, self).__init__()\n        \n        self.device = device\n        \n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.embedding = embedding\n        self.pretrained_embedding_loaded = pretrained_embedding_loaded\n        \n        self.attn_weights = nn.Sequential(\n            nn.Linear(hidden_size * 3, hidden_size, bias=False),\n            nn.Tanh(),\n            nn.Linear(hidden_size, 1, bias=False),\n            nn.Softmax(dim=1)\n        )\n        self.lstm = nn.LSTM(embedding_size + 2 * hidden_size, hidden_size, num_layers, dropout=0.0)\n        self.fc_out = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x, encoder_states, hidden, cell):\n        x = x.unsqueeze(0)\n        # x_shape: (seq_len=1, batch_size)\n        # hidden_shape: (1, batch_size, hidden_size)\n        # cell_shape: (1, batch_size, hidden_size)\n        encoder_states = torch.transpose(encoder_states, 1, 0)\n        # encoder_states_shape: (batch_size, seq_len, hidden_size * 2)\n        if self.pretrained_embedding_loaded:\n            with torch.no_grad():\n                embedding = self.embedding(x)\n        else:\n            embedding = self.embedding(x)\n        # embedding_shape: (seq_len=1, batch_size, embedding_size)\n        \n        seq_len = encoder_states.shape[1]\n        hidden_repeated = hidden.repeat(seq_len, 1, 1).permute(1, 0, 2)\n        # hidden_repeated_shape: (batch_size, seq_len, hidden_size)\n        \n        attn_weights = self.attn_weights(torch.cat((hidden_repeated, encoder_states), dim=2))\n        # attn_weights_shape: (batch_size, seq_len, 1)\n        \n        context_vec = torch.bmm(attn_weights.permute(0, 2, 1), encoder_states).permute(1, 0, 2)\n        # context_vec_shape: (1, batch_size, hidden_size * 2)\n        \n        combined = torch.cat((embedding, context_vec), dim=2)\n        # combined_shape: (1, batch_size, embedding_size + 2 * hidden_size)\n        \n        lstm_out, (hidden, cell) = self.lstm(combined, (hidden, cell))\n        # lstm_out_shape: (seq_len=1, batch_size, hidden_size)\n        fc_out = self.fc_out(lstm_out)\n        # fc_out_shape: (seq_len=1, batch_size, output_size)\n        \n        return fc_out, hidden, cell",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:39.352008Z",
     "iopub.execute_input": "2021-06-04T15:21:39.352344Z",
     "iopub.status.idle": "2021-06-04T15:21:39.363795Z",
     "shell.execute_reply.started": "2021-06-04T15:21:39.352312Z",
     "shell.execute_reply": "2021-06-04T15:21:39.362815Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class Seq2SeqModel(nn.Module):\n    def __init__(self, \n                 vocab_size, embedding_size, hidden_size, output_size,\n                 gender_input_size, tense_input_size, context_hidden_size, context_output_size,\n                 pad_idx, device, num_layers, dropout_p, pretrained_embedding=None):\n        super(Seq2SeqModel, self).__init__()\n        \n        self.device = device\n        self.num_layers = num_layers\n        \n        if pretrained_embedding is not None:\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding, padding_idx=pad_idx)\n            self.pretrained_embedding_loaded = True\n        else:\n            self.embedding = nn.Sequential(\n                nn.Embedding(vocab_size, embedding_size, padding_idx=pad_idx),\n                nn.Dropout(dropout_p)\n            )\n            self.pretrained_embedding_loaded = False\n        \n        self.context_mem = ContextMem(gender_input_size, tense_input_size, context_hidden_size, context_output_size, embedding_size, device).to(device)\n        self.encoder = EncoderRNN(vocab_size, embedding_size, hidden_size,\n                                  pad_idx, device, num_layers, dropout_p,\n                                  self.embedding, self.pretrained_embedding_loaded).to(device)\n        self.decoder = DecoderRNN(vocab_size, embedding_size, hidden_size, output_size,\n                                  pad_idx, device, num_layers, dropout_p,\n                                  self.embedding, self.pretrained_embedding_loaded).to(device)\n        \n        self.vocab_size = vocab_size\n        \n    def forward(self, input, target, context, teacher_forcing_ratio=0.5):\n        batch_size = input.shape[1]\n        target_len = target.shape[0]\n        target_vocab_size = self.vocab_size\n        \n        outputs = torch.zeros(target_len, batch_size, target_vocab_size, device=self.device)\n        \n        nsubj, gender, tense = context\n        # nsubj_shape:  (batch_size)\n        # gender_shape: (batch_size, gender_input_size)\n        # tense_shape:  (batch_size, tense_input_size)\n        if self.pretrained_embedding_loaded:\n            with torch.no_grad():\n                nsubj_embedding = self.embedding(nsubj).squeeze(0)\n        else:\n            nsubj_embedding = self.embedding(nsubj).squeeze(0)\n            # nsubj_embedding_shape: (batch_size, embedding_size)\n        \n        hidden = self.context_mem(nsubj_embedding, gender, tense)\n        cell = hidden.clone()\n        # hidden, cell shapes: (batch_size, context_output_size=hidden_size)\n        \n        hidden = torch.cat([hidden.unsqueeze(0)] * 2, 0)\n        cell = torch.cat([cell.unsqueeze(0)] * 2, 0)\n        # hidden, cell shapes: (2, batch_size, context_output_size=hidden_size)\n        \n        encoder_states, hidden, cell = self.encoder(input, hidden, cell)\n        # hidden, cell shapes: (2, batch_size, hidden_size)\n        # encoder_states_shape: (seq_len, batch_size, hidden_size * 2)\n        \n        prev_token_idx = target[0]\n        # prev_token_shape: (batch_size)\n        \n        for t in range(1, target_len):\n            output, hidden, cell = self.decoder(prev_token_idx, encoder_states, hidden, cell)\n            # output_shape: (1, batch_size, output_size)\n            outputs[t] = output.squeeze(0)\n            \n            best_prediction = outputs[t].argmax(dim=1)\n            # best_prediction_shape: (batch_size)\n            prev_token_idx = target[t] if random() < teacher_forcing_ratio else best_prediction\n        \n        return outputs",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:39.778691Z",
     "iopub.execute_input": "2021-06-04T15:21:39.778994Z",
     "iopub.status.idle": "2021-06-04T15:21:39.812117Z",
     "shell.execute_reply.started": "2021-06-04T15:21:39.778967Z",
     "shell.execute_reply": "2021-06-04T15:21:39.811074Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Обучение модели",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Функция сохранения текущего состояния модели",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def save_model(model, optimizer, epoch, path):\n    checkpoint = {\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'criterion': criterion,\n        'epoch': epoch\n    }\n    \n    torch.save(checkpoint, path)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:40.985472Z",
     "iopub.execute_input": "2021-06-04T15:21:40.985816Z",
     "iopub.status.idle": "2021-06-04T15:21:40.990038Z",
     "shell.execute_reply.started": "2021-06-04T15:21:40.985787Z",
     "shell.execute_reply": "2021-06-04T15:21:40.989189Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Функция загрузки уже тренировавшейся модели",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def load_model(model, optimizer, criterion, path, for_inference=True, device=torch.device('cpu')):\n    checkpoint = torch.load(path, map_location=device)\n\n    model.load_state_dict(checkpoint['model_state_dict'])\n    \n    if not for_inference:\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        epoch = checkpoint['epoch']\n        criterion = checkpoint['criterion']\n\n        return epoch",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:42.022259Z",
     "iopub.execute_input": "2021-06-04T15:21:42.022585Z",
     "iopub.status.idle": "2021-06-04T15:21:42.029191Z",
     "shell.execute_reply.started": "2021-06-04T15:21:42.022554Z",
     "shell.execute_reply": "2021-06-04T15:21:42.028197Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Инициализация гиперпараметров",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "learning_rate = 0.001\nbatch_size = 64\nepochs_amount = 50\nhidden_size = 1024\nembedding_size = 300\nnum_layers = 1\nmax_norm = 1.0\ndropout_p = 0.5\ngender_input_size = 4\ntense_input_size = 3\ncontext_hidden_size = hidden_size // 2\ncontext_output_size = hidden_size\npatience = 4\noutput_size = vocab_size\npad_idx = text_transformer.special_tokens_to_idx.get('<pad>')\nmodel_path = '../models/'\nmodel_name = 'seq2seq_attention.model'",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:46.583935Z",
     "iopub.execute_input": "2021-06-04T15:21:46.584254Z",
     "iopub.status.idle": "2021-06-04T15:21:46.591032Z",
     "shell.execute_reply.started": "2021-06-04T15:21:46.584223Z",
     "shell.execute_reply": "2021-06-04T15:21:46.589912Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:48.765426Z",
     "iopub.execute_input": "2021-06-04T15:21:48.765789Z",
     "iopub.status.idle": "2021-06-04T15:21:48.813281Z",
     "shell.execute_reply.started": "2021-06-04T15:21:48.765758Z",
     "shell.execute_reply": "2021-06-04T15:21:48.812375Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model = Seq2SeqModel(vocab_size, embedding_size, hidden_size, output_size,\n                     gender_input_size, tense_input_size, context_hidden_size, context_output_size, \n                     pad_idx, device, num_layers, dropout_p).to(device)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:49.048917Z",
     "iopub.execute_input": "2021-06-04T15:21:49.049234Z",
     "iopub.status.idle": "2021-06-04T15:21:55.995325Z",
     "shell.execute_reply.started": "2021-06-04T15:21:49.049203Z",
     "shell.execute_reply": "2021-06-04T15:21:55.994459Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:55.996779Z",
     "iopub.execute_input": "2021-06-04T15:21:55.997106Z",
     "iopub.status.idle": "2021-06-04T15:21:56.002322Z",
     "shell.execute_reply.started": "2021-06-04T15:21:55.997069Z",
     "shell.execute_reply": "2021-06-04T15:21:56.001464Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:56.004060Z",
     "iopub.execute_input": "2021-06-04T15:21:56.004553Z",
     "iopub.status.idle": "2021-06-04T15:21:56.011502Z",
     "shell.execute_reply.started": "2021-06-04T15:21:56.004501Z",
     "shell.execute_reply": "2021-06-04T15:21:56.010748Z"
    },
    "trusted": true
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "try:\n    epoch = load_model(model, optimizer, criterion, model_path + model_name, for_inference=False)\n    print(f'Loaded model from {model_path}')\nexcept:\n    print(f'No models found at {model_path}')\n    epoch = 1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:56.013228Z",
     "iopub.execute_input": "2021-06-04T15:21:56.013588Z",
     "iopub.status.idle": "2021-06-04T15:21:56.022056Z",
     "shell.execute_reply.started": "2021-06-04T15:21:56.013550Z",
     "shell.execute_reply": "2021-06-04T15:21:56.021049Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": "No models found at ./\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Урезание данных для соответствия размеру батча",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_lemm_tensor_f = cut_to_fit_batch(train_lemm_tensor, batch_size)\ntrain_orig_tensor_f = cut_to_fit_batch(train_orig_tensor, batch_size)\n\ntest_lemm_tensor_f = cut_to_fit_batch(test_lemm_tensor, batch_size)\ntest_orig_tensor_f = cut_to_fit_batch(test_orig_tensor, batch_size)\n\nval_lemm_tensor_f = cut_to_fit_batch(val_lemm_tensor, batch_size)\nval_orig_tensor_f = cut_to_fit_batch(val_orig_tensor, batch_size)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:56.023474Z",
     "iopub.execute_input": "2021-06-04T15:21:56.023898Z",
     "iopub.status.idle": "2021-06-04T15:21:56.033193Z",
     "shell.execute_reply.started": "2021-06-04T15:21:56.023858Z",
     "shell.execute_reply": "2021-06-04T15:21:56.032389Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_context_tensors_f = [cut_to_fit_batch(tensor.unsqueeze(0), batch_size).squeeze(1) for tensor in train_context_tensors]\ntest_context_tensors_f = [cut_to_fit_batch(tensor.unsqueeze(0), batch_size).squeeze(1) for tensor in test_context_tensors]\nval_context_tensors_f = [cut_to_fit_batch(tensor.unsqueeze(0), batch_size).squeeze(1) for tensor in val_context_tensors]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:56.034470Z",
     "iopub.execute_input": "2021-06-04T15:21:56.034841Z",
     "iopub.status.idle": "2021-06-04T15:21:56.044400Z",
     "shell.execute_reply.started": "2021-06-04T15:21:56.034806Z",
     "shell.execute_reply": "2021-06-04T15:21:56.043551Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Инициализация данных итерируемых по батчам",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_dataset = TensorDataset(train_lemm_tensor_f, train_orig_tensor_f, *train_context_tensors_f)\ntest_dataset = TensorDataset(test_lemm_tensor_f, test_orig_tensor_f, *test_context_tensors_f)\nval_dataset = TensorDataset(val_lemm_tensor_f, val_orig_tensor_f, *val_context_tensors_f)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:56.045743Z",
     "iopub.execute_input": "2021-06-04T15:21:56.046204Z",
     "iopub.status.idle": "2021-06-04T15:21:56.052477Z",
     "shell.execute_reply.started": "2021-06-04T15:21:56.046165Z",
     "shell.execute_reply": "2021-06-04T15:21:56.051613Z"
    },
    "trusted": true
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_loader = DataLoader(train_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=1)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:56.054572Z",
     "iopub.execute_input": "2021-06-04T15:21:56.054997Z",
     "iopub.status.idle": "2021-06-04T15:21:56.062395Z",
     "shell.execute_reply.started": "2021-06-04T15:21:56.054960Z",
     "shell.execute_reply": "2021-06-04T15:21:56.061101Z"
    },
    "trusted": true
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Определение функции проверки работы сети между эпохами обучения",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def test_evaluate(model, input, context, target_len=45):\n    with torch.no_grad():\n        model.eval()\n        \n        input = input.to(device)\n\n        nsubj, gender, tense = context\n        nsubj_embedding = model.decoder.embedding(nsubj)\n\n        hidden = model.context_mem(nsubj_embedding, gender, tense)\n        cell = hidden.clone()\n\n        if model.num_layers == 1:\n            hidden.unsqueeze_(0)\n            cell.unsqueeze_(0)\n            # hidden, cell shapes: (1, batch_size, context_output_size=hidden_size)\n        else:\n            hidden = torch.cat([hidden.unsqueeze(0)] * model.num_layers, 0)\n            cell = torch.cat([cell.unsqueeze(0)] * model.num_layers, 0)\n            # hidden, cell shapes: (num_layers, batch_size, context_output_size=hidden_size)\n\n        sos_idx = text_transformer.special_tokens_to_idx.get('<sos>')\n        eos_idx = text_transformer.special_tokens_to_idx.get('<eos>')\n    \n        encoder_states, hidden, cell = model.encoder(input, hidden, cell)\n        \n        predicted_indexes = [sos_idx]\n        \n        for _ in range(1, target_len):\n            prev_idx = torch.tensor([predicted_indexes[-1]], dtype=torch.long, device=device)\n            \n            output, hidden, cell = model.decoder(prev_idx, encoder_states, hidden, cell)\n            output = output.squeeze(0)\n            \n            best_prediction = output.argmax(dim=1).item()\n            \n            if best_prediction == eos_idx:\n                break\n                \n            predicted_indexes.append(best_prediction)\n                        \n        \n    predicted_tokens = [text_transformer.vocab.idx_to_token(idx) for idx in predicted_indexes]\n    return predicted_tokens[1:]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:57.119829Z",
     "iopub.execute_input": "2021-06-04T15:21:57.120138Z",
     "iopub.status.idle": "2021-06-04T15:21:57.130175Z",
     "shell.execute_reply.started": "2021-06-04T15:21:57.120108Z",
     "shell.execute_reply": "2021-06-04T15:21:57.129329Z"
    },
    "trusted": true
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Определение функции обучения сети",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def train(model, optimizer, criterion, train_data, val_data, test_data, epochs_amount, max_norm, patience=3, current_epoch=1, n_prints=5):\n    min_mean_val_loss = float('+inf')\n    initial_patiece = patience\n    print_every = len(train_data) // n_prints\n    \n    for epoch in tqdm(range(current_epoch, epochs_amount + 1), 'Epochs'):\n        print(f'\\nEpoch [{epoch} / {epochs_amount}]')\n        \n        model.train()\n        for iteration, (input, target, nsubj, gender, tense) in enumerate(tqdm(train_data, 'Epoch training iterations')):\n            optimizer.zero_grad()\n            # input = lemm_texts, target = orig_texts\n            \n            input = torch.transpose(input, 1, 0).to(device)\n            # input_shape: (seq_len, batch_size)\n            \n            target = torch.transpose(target, 1, 0).to(device)\n            # target_shape: (seq_len, batch_size)\n            \n            context = (nsubj.to(device), gender.to(device), tense.to(device))\n            \n            output = model(input, target, context)\n            # output_shape: (seq_len, batch_size, vocab_size) but need (N, vocab_size)\n            \n            target = target[1:].reshape(-1)\n            # now target_shape is (seq_len * batch_size)\n            \n            vocab_size = output.shape[2]\n            \n            output = output[1:].reshape(-1, vocab_size)\n            # now output_shape is (seq_len * batch_size, vocab_size)\n            \n            loss = criterion(output, target)\n            loss.backward()\n            \n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n            \n            optimizer.step()\n            \n            if iteration % print_every == 0:\n                print(f'\\tIteration #{iteration}: training loss = {loss.item()}')\n            elif iteration == len(train_data):\n                print(f'\\tIteration #{iteration}: training loss = {loss.item()}')\n            \n            \n        with torch.no_grad():\n            model.eval()\n            val_loss = []\n            \n            for input, target, nsubj, gender, tense in tqdm(val_data, 'Epoch validating iterations'):\n                input = torch.transpose(input, 1, 0).to(device)\n                target = torch.transpose(target, 1, 0).to(device)\n                context = (nsubj.to(device), gender.to(device), tense.to(device))\n                \n                output = model(input, target, context)\n                vocab_size = output.shape[2]\n                output = output[1:].reshape(-1, orig_vocab_size)\n                target = target[1:].reshape(-1)\n                \n                val_loss.append(criterion(output, target).item())\n            \n            mean_val_loss = sum(val_loss) / len(val_loss)\n            print(f'\\tValidation loss = {mean_val_loss}')\n            if mean_val_loss < min_mean_val_loss:\n                try:\n                    save_model(model, optimizer, epoch, model_path + model_name)\n                    min_mean_val_loss = mean_val_loss\n                    patience = initial_patiece\n                except Exception as exc:\n                    print(exc)\n            else:\n                patience -= 1\n            \n            test_data = DataLoader(test_data.dataset, batch_size=1, shuffle=True)\n            for input, target, nsubj, gender, tense in test_data:\n                target = target.squeeze(0).to(device)\n                context = (nsubj.to(device), gender.to(device), tense.to(device))\n                \n                input = torch.transpose(input, 1, 0)\n                target_len = target.shape[0]\n                \n                output = test_evaluate(model, input, context, target_len)\n                decoded_input = [text_transformer.vocab.idx_to_token(idx.item()) for idx in input]\n                decoded_target = [text_transformer.vocab.idx_to_token(idx.item()) for idx in target]\n                \n                print(f'\\tInput: {decoded_input}')\n                print(f'\\tOutput: {output}')\n                print(f'\\tTarget: {decoded_target}')\n                break\n        \n        if patience == 0:\n            print(f'\\nModel learning finished due to early stopping')\n            break\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:57.784005Z",
     "iopub.execute_input": "2021-06-04T15:21:57.784314Z",
     "iopub.status.idle": "2021-06-04T15:21:57.803270Z",
     "shell.execute_reply.started": "2021-06-04T15:21:57.784284Z",
     "shell.execute_reply": "2021-06-04T15:21:57.802263Z"
    },
    "trusted": true
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Определение функции эксплуатации обученной модели",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def evaluate(model: Seq2SeqModel, sentence: str, context, max_seq_len=45):\n    with torch.no_grad():\n        model.eval()\n        \n        nsubj, gender, tense = context\n        \n        nsubj = torch.tensor([text_transformer.vocab.token_to_idx(nsubj)], device=device).unsqueeze(0)\n        gender = torch.tensor([gender_to_vec[gender]], dtype=torch.float32, device=device)\n        tense = torch.tensor([tense_to_vec[tense]], dtype=torch.float32, device=device)\n        \n        nsubj_embedding = model.decoder.embedding(nsubj).squeeze(0)\n\n        hidden = model.context_mem(nsubj_embedding, gender, tense)\n        cell = hidden.clone()\n\n        if model.num_layers == 1:\n            hidden.unsqueeze_(0)\n            cell.unsqueeze_(0)\n            # hidden, cell shapes: (1, batch_size, context_output_size=hidden_size)\n        else:\n            hidden = torch.cat([hidden.unsqueeze(0)] * model.num_layers, 0)\n            cell = torch.cat([cell.unsqueeze(0)] * model.num_layers, 0)\n            # hidden, cell shapes: (num_layers, batch_size, context_output_size=hidden_size)\n        \n        input_tensor = text_transformer.text_to_tensor(sentence, max_seq_len).to(device)\n        input_tensor = torch.transpose(input_tensor, 1, 0)\n        sos_idx = text_transformer.special_tokens_to_idx.get('<sos>')\n        eos_idx = text_transformer.special_tokens_to_idx.get('<eos>')\n    \n    \n        encoder_states, hidden, cell = model.encoder(input_tensor)\n        \n        predicted_indexes = [sos_idx]\n        \n#         while True:\n#             prev_idx = torch.tensor([predicted_indexes[-1]], dtype=torch.long, device=device)\n            \n#             output, hidden, cell = model.decoder(prev_idx, hidden, cell)\n#             output = output.squeeze(0)\n            \n#             best_prediction = output.argmax(dim=1).item()\n            \n#             if best_prediction == eos_idx:\n#                 break\n            \n#             predicted_indexes.append(best_prediction)\n                       \n        \n        for _ in range(1, max_seq_len):\n            prev_idx = torch.tensor([predicted_indexes[-1]], dtype=torch.long, device=device)\n            \n            output, hidden, cell = model.decoder(prev_idx, encoder_states, hidden, cell)\n            output = output.squeeze(0)\n            \n            best_prediction = output.argmax(dim=1).item()\n            \n            if best_prediction == eos_idx:\n                break\n                \n            predicted_indexes.append(best_prediction)\n        \n    predicted_tokens = [text_transformer.vocab.idx_to_token(idx) for idx in predicted_indexes]\n    return predicted_tokens[1:]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:21:58.575012Z",
     "iopub.execute_input": "2021-06-04T15:21:58.575341Z",
     "iopub.status.idle": "2021-06-04T15:21:58.589763Z",
     "shell.execute_reply.started": "2021-06-04T15:21:58.575310Z",
     "shell.execute_reply": "2021-06-04T15:21:58.588888Z"
    },
    "trusted": true
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train(model, optimizer, criterion, train_loader, val_loader, test_loader, epochs_amount, max_norm, patience, epoch)",
   "metadata": {
    "tags": [],
    "execution": {
     "iopub.status.busy": "2021-06-04T15:22:02.720428Z",
     "iopub.execute_input": "2021-06-04T15:22:02.720799Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Epochs:   0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2f4581c4e0e4ec0b732bbb1307fdf82"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "\nEpoch [1 / 50]\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Epoch training iterations:   0%|          | 0/13026 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80b9d895eacc41c5abc8b4916fae4cdf"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "\tIteration #0: training loss = 11.735000610351562\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# import gc\n# del model\n# del optimizer\n# gc.collect()\n# torch.cuda.empty_cache()\n# gc.collect()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-04T15:07:34.102825Z",
     "iopub.execute_input": "2021-06-04T15:07:34.103145Z",
     "iopub.status.idle": "2021-06-04T15:07:34.722069Z",
     "shell.execute_reply.started": "2021-06-04T15:07:34.103115Z",
     "shell.execute_reply": "2021-06-04T15:07:34.721236Z"
    },
    "trusted": true
   },
   "execution_count": 58,
   "outputs": [
    {
     "execution_count": 58,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "test_sample = test_df.sample(10)\ntest_input = test_sample.lemm_texts.to_list()\ntest_target = test_sample.orig_texts.to_list()\ntest_pair = list(zip(test_input, test_target))",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "for input_sentence, target_sentence in test_pair:\n    model_output = evaluate(model, input_sentence, max_seq_len)\n    print(f'Input: {input_sentence}')\n    print(f'Output: {model_output}')\n    print(f'Target: {target_sentence}')\n    print('\\n')",
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "test_input = test_df.lemm_texts.to_list()\ntest_target = test_df.orig_texts.to_list()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "outputs = [evaluate(model, input, 50) for input in tqdm(test_input)]\ntargets = [[orig_text_transformer.tokenize(target)] for target in tqdm(test_target)]",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "score = round(bleu_score(outputs, targets, max_n=1, weights=[1]), 3)\nscore",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}