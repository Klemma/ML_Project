{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sealed-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "from random import random, sample\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from functools import reduce\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "narrow-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts = []\n",
    "orig_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brutal-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lemmatized_texts.txt', 'r', encoding='utf-8') as f:\n",
    "    lemm_texts = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interracial-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('original_texts.txt', 'r', encoding='utf-8') as f:\n",
    "    orig_texts = f.read().lower().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a531983-e103-4f98-9845-6f79bab7ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=zip(lemm_texts, orig_texts), columns=['lemm_texts', 'orig_texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84616b9a-d824-48b2-886c-53bc6cf55a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemm_texts</th>\n",
       "      <th>orig_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>я предлагать оригинальный подарок для малыш!</td>\n",
       "      <td>я предлагаю оригинальный подарок для малыша!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>я обезательный перезвонить в любой случай.</td>\n",
       "      <td>я обезательно перезвоню в любом случае.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>цена на память я не помнить.</td>\n",
       "      <td>цены на память я не помню.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>я не помнить , где находиться.</td>\n",
       "      <td>я не помню, где находились.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>я работать на высококачественный американский ...</td>\n",
       "      <td>я работаю на высококачественных американских м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360274</th>\n",
       "      <td>зелёный ящерица застылый на мраморный ступень.</td>\n",
       "      <td>зеленая ящерица застыла на мраморной ступени.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360275</th>\n",
       "      <td>больший ящерица шмыгнуть по песок.</td>\n",
       "      <td>большая ящерица шмыгнула по песку.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360276</th>\n",
       "      <td>домашний ящерица быстро пробежать вдоль штора.</td>\n",
       "      <td>домашняя ящерица быстро пробежала вдоль штор.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360277</th>\n",
       "      <td>крошечный ящерка сбежать с валун.</td>\n",
       "      <td>крошечная ящерка сбежала с валуна.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360278</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360279 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lemm_texts  \\\n",
       "0            я предлагать оригинальный подарок для малыш!   \n",
       "1              я обезательный перезвонить в любой случай.   \n",
       "2                            цена на память я не помнить.   \n",
       "3                          я не помнить , где находиться.   \n",
       "4       я работать на высококачественный американский ...   \n",
       "...                                                   ...   \n",
       "360274     зелёный ящерица застылый на мраморный ступень.   \n",
       "360275                 больший ящерица шмыгнуть по песок.   \n",
       "360276     домашний ящерица быстро пробежать вдоль штора.   \n",
       "360277                  крошечный ящерка сбежать с валун.   \n",
       "360278                                                      \n",
       "\n",
       "                                               orig_texts  \n",
       "0            я предлагаю оригинальный подарок для малыша!  \n",
       "1                 я обезательно перезвоню в любом случае.  \n",
       "2                              цены на память я не помню.  \n",
       "3                             я не помню, где находились.  \n",
       "4       я работаю на высококачественных американских м...  \n",
       "...                                                   ...  \n",
       "360274      зеленая ящерица застыла на мраморной ступени.  \n",
       "360275                 большая ящерица шмыгнула по песку.  \n",
       "360276      домашняя ящерица быстро пробежала вдоль штор.  \n",
       "360277                 крошечная ящерка сбежала с валуна.  \n",
       "360278                                                     \n",
       "\n",
       "[360279 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exterior-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens: List[str], unk_idx: int):\n",
    "        self._tokens = tokens\n",
    "        self._token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
    "        self._unk_idx = unk_idx\n",
    "        \n",
    "    def token_to_idx(self, token: str) -> int:\n",
    "        return self._token_to_idx.get(token, self._unk_idx)\n",
    "    \n",
    "    def idx_to_token(self, idx: int) -> str:\n",
    "        return self._tokens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "transsexual-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTransformer:\n",
    "    def __init__(self, vocab_size: int):\n",
    "        self.vocab = None\n",
    "        self.vocab_size = vocab_size\n",
    "        self.special_tokens_to_idx = {'<UNK>': 0, '<PAD>': 1, '<SOS>': 2, '<EOS>': 3}\n",
    "        self._tokenizer = nltk.tokenize.wordpunct_tokenize\n",
    "    \n",
    "    def tokenize(self, text) -> List[str]:\n",
    "        return self._tokenizer(text.lower())\n",
    "    \n",
    "    def build_vocab(self, tokens: List[str]):\n",
    "        tokens_ = [special_token for special_token in self.special_tokens_to_idx.keys()]\n",
    "        special_tokens_amount = len(self.special_tokens_to_idx)\n",
    "        \n",
    "        for token, _ in Counter(tokens).most_common(self.vocab_size - special_tokens_amount):\n",
    "            tokens_.append(token)\n",
    "        \n",
    "        unk_idx = self.special_tokens_to_idx.get('<UNK>')\n",
    "        self.vocab = Vocab(tokens_, unk_idx)\n",
    "        \n",
    "    def transform_text(self, text: str) -> List[int]:\n",
    "        tokenized_text = self.tokenize(text)\n",
    "        transformed = [self.vocab.token_to_idx(token) for token in tokenized_text]\n",
    "        return transformed\n",
    "    \n",
    "    def fit_transform(self, texts: List[str]) -> None:\n",
    "        transformed_texts = []\n",
    "        \n",
    "        tokenized_texts = [self.tokenize(text) for text in tqdm(texts, 'Tokenizing texts')]\n",
    "        tokens = chain(*tokenized_texts)\n",
    "        self.build_vocab(tokens)\n",
    "        \n",
    "        for tokenized_text in tqdm(tokenized_texts, 'Transforming texts'):\n",
    "            transformed = [self.vocab.token_to_idx(token) for token in tokenized_text]\n",
    "            transformed_texts.append(transformed)\n",
    "    \n",
    "    def transform_texts(self, texts: List[str]) -> List[List[int]]:\n",
    "        transformed_texts = [transform_text(text) for text in tqdm(texts, 'Transforming texts')]\n",
    "        return transformed_texts\n",
    "    \n",
    "    def text_to_tensor(self, text: str, max_seq_len=10) -> torch.tensor:\n",
    "        transformed_text = self.transform_text(text)\n",
    "        pad_idx = self.special_tokens_to_idx.get('<PAD>')\n",
    "        sos_idx = self.special_tokens_to_idx.get('<SOS>')\n",
    "        eos_idx = self.special_tokens_to_idx.get('<EOS>')\n",
    "        \n",
    "        if len(transformed_text) >= max_seq_len:\n",
    "            transformed_text = transformed_text[:max_seq_len]\n",
    "        else:\n",
    "            pad_size = max_seq_len - len(transformed_text)\n",
    "            transformed_text.extend([pad_idx] * pad_size)   \n",
    "        transformed_text.insert(0, sos_idx)\n",
    "        transformed_text.append(eos_idx)\n",
    "        \n",
    "        tensor = torch.tensor(transformed_text, dtype=torch.long)\n",
    "        return tensor.unsqueeze(0)\n",
    "    \n",
    "    def texts_to_tensor(self, texts: List[str], max_seq_len=10) -> torch.tensor:\n",
    "        pad_idx = self.special_tokens_to_idx.get('<PAD>')\n",
    "        sos_idx = self.special_tokens_to_idx.get('<SOS>')\n",
    "        eos_idx = self.special_tokens_to_idx.get('<EOS>')\n",
    "        transformed_texts = []\n",
    "        \n",
    "        for text in tqdm(texts, 'Building tensor'):\n",
    "            transformed_text = self.transform_text(text)\n",
    "            if len(transformed_text) >= max_seq_len:\n",
    "                transformed_text = transformed_text[:max_seq_len]\n",
    "            else:\n",
    "                pad_size = max_seq_len - len(transformed_text)\n",
    "                transformed_text.extend([pad_idx] * pad_size)   \n",
    "            transformed_text.insert(0, sos_idx)\n",
    "            transformed_text.append(eos_idx)\n",
    "            transformed_texts.append(transformed_text)\n",
    "        \n",
    "        tensor = torch.tensor(transformed_texts, dtype=torch.long)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "convinced-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 35000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9529aad-ce28-446e-a8f6-72f442f94bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = model_selection.train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6507858a-1929-447e-b483-b6f8e6c67a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, val_df = model_selection.train_test_split(test_df, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba4035fb-9b8c-4de0-88c1-3b80f786a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_text_transformer = TextTransformer(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea9c94b-6a15-4118-b96f-47c84f1275d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e4e65b2b544902bc9a00586510c1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing texts:   0%|          | 0/324251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2921104296144d3b843575e6e5fefb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transforming texts:   0%|          | 0/324251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemm_text_transformer.fit_transform(train_df.lemm_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "696abc39-9d90-4817-a32a-dcb5a76936e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47aa12e8a334e588439c9d78b8b7e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/324251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e882b30be1241239d544e88597eae4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/18014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e320a713ea40849602a75faf90bc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/18014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_lemm_tensor = lemm_text_transformer.texts_to_tensor(list(train_df.lemm_texts))\n",
    "test_lemm_tensor = lemm_text_transformer.texts_to_tensor(list(test_df.lemm_texts))\n",
    "val_lemm_tensor = lemm_text_transformer.texts_to_tensor(list(val_df.lemm_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bff769f-aa07-40f4-bdc9-0aca43361df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_text_transformer = TextTransformer(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a62d91da-46c8-4f15-883d-1feafb66d016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b21c1889fbd43a9bc6fba6e2f53f8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing texts:   0%|          | 0/324251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98fde543cac47f598c803b6d030123d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transforming texts:   0%|          | 0/324251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_text_transformer.fit_transform(train_df.orig_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1f6dffe-0743-4a9b-9226-aab9ccbee5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625cfdf84300425896c565384cb01e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/324251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bace525ca5e4483bdcd2d2924cfd666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/18014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423d3034dbcd4780b7d56c29e0f993ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building tensor:   0%|          | 0/18014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_orig_tensor = orig_text_transformer.texts_to_tensor(list(train_df.orig_texts))\n",
    "test_orig_tensor = orig_text_transformer.texts_to_tensor(list(test_df.orig_texts))\n",
    "val_orig_tensor = orig_text_transformer.texts_to_tensor(list(val_df.orig_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89649d79-564c-4de1-b311-b4714893ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lemm_tensor = torch.transpose(train_lemm_tensor, 1, 0)\n",
    "# test_lemm_tensor = torch.transpose(test_lemm_tensor, 1, 0)\n",
    "# val_lemm_tensor = torch.transpose(val_lemm_tensor, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b219e367-5304-4ac5-bb11-33906cc63d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_orig_tensor = torch.transpose(train_orig_tensor, 1, 0)\n",
    "# test_orig_tensor = torch.transpose(test_orig_tensor, 1, 0)\n",
    "# val_orig_tensor = torch.transpose(val_orig_tensor, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e4188ea-e38a-4ad0-b1b0-dd802e13ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, hidden_size: int, pad_idx: int):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, pad_idx)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x_shape: (seq_len, batch_size)\n",
    "        embedding = self.embedding(x)\n",
    "        \n",
    "        # embedding_shape: (seq_len, batch_size, embedding_size)\n",
    "        output, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # output_shape: (seq_len, batch_size, hidden_size)\n",
    "        # hidden_shape: 2 tensors of (1, batch_size, hidden_size)\n",
    "        return output, (hidden, cell)\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aebceb47-203d-4f25-86fe-fdcebd5f9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, hidden_size: int, output_size: int, pad_idx):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, pad_idx)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        embedding = self.embedding(x)\n",
    "        output, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        output = self.fc(output)\n",
    "        output = output.squeeze(0)\n",
    "        output = self.softmax(output)\n",
    "        return output, (hidden, cell)\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18ca3002-d776-4eea-92a5-ed269f6ed16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, output_size, pad_idx):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.encoder = EncoderRNN(vocab_size, embedding_size, hidden_size, pad_idx).to(device)\n",
    "        self.decoder = DecoderRNN(vocab_size, embedding_size, hidden_size, output_size, pad_idx).to(device)\n",
    "        \n",
    "    def forward(self, input_tensor, target_tensor, hidden, cell, teacher_force_ratio=0.5):\n",
    "        input_tensor = torch.transpose(input_tensor, 1, 0)\n",
    "        target_tensor = torch.transpose(target_tensor, 1, 0)\n",
    "        # input_tensor_shape: (seq_len, batch_size)\n",
    "        # target_tensor_shape: (seq_len, batch_size)\n",
    "        batch_size = input_tensor.shape[1]\n",
    "        seq_len = target_tensor.shape[0]\n",
    "        \n",
    "        outputs = torch.zeros(seq_len, batch_size, self.vocab_size, device=device)\n",
    "        \n",
    "#         hidden, cell = self.encoder(input_tensor, hidden)\n",
    "        _, (hidden, cell) = self.encoder(input_tensor, hidden, cell)\n",
    "        # hidden_shape: 2 tensors of (1, batch_size, hidden_size)\n",
    "        \n",
    "        x = target_tensor[0]\n",
    "        \n",
    "        for t in range(1, seq_len):\n",
    "            output, (hidden, cell) = self.decoder(x, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            best_prediction = output.argmax(1)\n",
    "            x = target_tensor[t] if random() < teacher_force_ratio else best_prediction\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f73d3069-8f55-47ff-97af-ae49e6cd1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "vocab_size = 35000\n",
    "hidden_size = 1024\n",
    "embedding_size = 300\n",
    "output_size = vocab_size\n",
    "pad_idx = lemm_text_transformer.special_tokens_to_idx.get('<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ccd5a7c-278e-4715-b631-a7a85cad0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(vocab_size, embedding_size, hidden_size, output_size, pad_idx).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72f935f4-2aad-4b58-b4aa-7ca3d8c55ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efb57a36-afb4-4057-ab6f-6cf624bbed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78d6b600-dfa1-477d-bae7-190a5b8ec87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_orig_tensor, train_lemm_tensor)\n",
    "test_dataset = TensorDataset(test_orig_tensor, test_lemm_tensor)\n",
    "val_dataset = TensorDataset(val_orig_tensor, val_lemm_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ff5a55e-7472-4f56-9549-89afc29682dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6404084-8f64-4684-a950-5c7e3e91f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_lemm(inp):\n",
    "    idx_to_token = lemm_text_transformer.vocab.idx_to_token\n",
    "    tokens = map(lambda idx: idx_to_token(idx), inp)\n",
    "    return reduce(lambda lhs, rhs: lhs + ' ' + rhs, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e6eec53-e300-4327-b5bf-8e8d5b478879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_orig(inp):\n",
    "    idx_to_token = orig_text_transformer.vocab.idx_to_token\n",
    "    tokens = map(lambda idx: idx_to_token(idx), inp)\n",
    "    return reduce(lambda lhs, rhs: lhs + ' ' + rhs, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00f8a543-2113-4d68-bcf4-e503e85ad49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, val_loader, optimizer, criterion, epochs, lr, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}]')\n",
    "        hidden = model.encoder.initHidden(batch_size)\n",
    "        cell = model.encoder.initHidden(batch_size)\n",
    "        \n",
    "        for iteration, (target_data, input_data) in enumerate(data_loader):\n",
    "            target_data = target_data.to(device)\n",
    "            input_data = input_data.to(device)\n",
    "            try:\n",
    "                output = model(input_data, target_data, hidden, cell)\n",
    "            except:\n",
    "                break\n",
    "            target_data = torch.transpose(target_data, 0, 1)\n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            target_data = target_data[1:].reshape(-1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target_data)\n",
    "            training_loss = loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration % 2500 == 0:\n",
    "                print(f'\\tIteration #{iteration}: training_loss = {training_loss}')\n",
    "            if (iteration + 1) % 5000 == 0:\n",
    "                with torch.no_grad():\n",
    "                    val_hidden = model.encoder.initHidden(batch_size)\n",
    "                    val_cell = model.encoder.initHidden(batch_size)\n",
    "                    val_loss_list = []\n",
    "                    for val_iteration, (val_target_data, val_input_data) in enumerate(val_loader):\n",
    "                        val_target_data = val_target_data.to(device)\n",
    "                        val_input_data = val_input_data.to(device)\n",
    "                        try:\n",
    "                            val_output = model(val_input_data, val_target_data, val_hidden, val_cell)\n",
    "                        except:\n",
    "                            break\n",
    "                        val_target_data = torch.transpose(val_target_data, 0, 1)\n",
    "                        val_output = val_output[1:].reshape(-1, val_output.shape[2])\n",
    "                        val_target_data = val_target_data[1:].reshape(-1)\n",
    "                        val_loss = criterion(val_output, val_target_data)\n",
    "                        val_loss_list.append(val_loss.item())\n",
    "                    print(f\"Validation loss: {sum(val_loss_list) / len(val_loss_list)}\")\n",
    "                    \n",
    "                    first_x = sample(list(iter(val_loader)), 1)[0]\n",
    "                    print(f\"Input: {decode_lemm(first_x[1][0])}\")\n",
    "                    print(f\"Target: {decode_orig(first_x[0][0])}\")\n",
    "                    val_hidden = model.encoder.initHidden(batch_size)\n",
    "                    val_cell = model.encoder.initHidden(batch_size)\n",
    "                    out = model(first_x[1].to(device), first_x[0].to(device), val_hidden, val_cell, 0.5)\n",
    "                    out = out.argmax(dim=2)\n",
    "                    out = torch.transpose(out, 0, 1)\n",
    "                    print(f\"Output: {decode_orig(out[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1aa3a9e-0623-47e4-b938-fa2896374f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "\tIteration #0: training_loss = 10.470785140991211\n",
      "\tIteration #2500: training_loss = 2.679882764816284\n",
      "Validation loss: 1.8701063526058537\n",
      "Input: <SOS> он пошевелиться на сидение . <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Target: <SOS> он пошевелился на сиденье . <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Output: <UNK> он <UNK> на сиденье . . . <EOS> <EOS> <EOS> <EOS>\n",
      "\tIteration #5000: training_loss = 1.9530543088912964\n",
      "Epoch [2/50]\n",
      "\tIteration #0: training_loss = 2.148900270462036\n",
      "\tIteration #2500: training_loss = 1.3579150438308716\n",
      "Validation loss: 1.0511523572151347\n",
      "Input: <SOS> форд помахать в ответ . <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Target: <SOS> форд помахал в ответ . <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Output: <UNK> <UNK> помахал в ответ . . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\tIteration #5000: training_loss = 1.0579689741134644\n",
      "Epoch [3/50]\n",
      "\tIteration #0: training_loss = 1.197873830795288\n",
      "\tIteration #2500: training_loss = 0.6647981405258179\n",
      "Validation loss: 0.6703477211270044\n",
      "Input: <SOS> я село за стол ... <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Target: <SOS> я села за стол ... <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Output: <UNK> я села за стол ... ... <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\tIteration #5000: training_loss = 0.6183029413223267\n",
      "Epoch [4/50]\n",
      "\tIteration #0: training_loss = 0.7048182487487793\n",
      "\tIteration #2500: training_loss = 0.3634636700153351\n",
      "Validation loss: 0.49743586258956124\n",
      "Input: <SOS> я устало прислониться к стена . <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Target: <SOS> я устало прислонился к стене . <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Output: <UNK> я устало прислонился к стене . . <EOS> <EOS> <EOS> <EOS>\n",
      "\tIteration #5000: training_loss = 0.37527742981910706\n",
      "Epoch [5/50]\n",
      "\tIteration #0: training_loss = 0.4082983136177063\n",
      "\tIteration #2500: training_loss = 0.21991565823554993\n",
      "Validation loss: 0.41312770211399663\n",
      "Input: <SOS> мы подходить к край . <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Target: <SOS> мы подходим к краю . <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Output: <UNK> мы подходим к краю . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\tIteration #5000: training_loss = 0.23614291846752167\n",
      "Epoch [6/50]\n",
      "\tIteration #0: training_loss = 0.2435867339372635\n",
      "\tIteration #2500: training_loss = 0.12677040696144104\n",
      "Validation loss: 0.3707838045214419\n",
      "Input: <SOS> лёнька осторожно подняться на обрыв ; <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Target: <SOS> ленька осторожно поднялся на обрыв ; <PAD> <PAD> <PAD> <PAD> <EOS>\n",
      "Output: <UNK> ленька осторожно поднялся на обрыв ; <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\tIteration #5000: training_loss = 0.14261828362941742\n",
      "Epoch [7/50]\n",
      "\tIteration #0: training_loss = 0.13436073064804077\n",
      "\tIteration #2500: training_loss = 0.08155817538499832\n",
      "Validation loss: 0.34826095322697187\n",
      "Input: <SOS> они вновь идти на <UNK> рынок . <PAD> <PAD> <PAD> <EOS>\n",
      "Target: <SOS> они вновь идут на <UNK> <UNK> . <PAD> <PAD> <PAD> <EOS>\n",
      "Output: <UNK> они вновь шли на <UNK> рынок . . <EOS> <EOS> <EOS>\n",
      "\tIteration #5000: training_loss = 0.08812379837036133\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-7ab96bf66d82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-28e83098de98>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, val_loader, optimizer, criterion, epochs, lr, batch_size)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\iluxa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\iluxa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train(model, train_loader, val_loader, optimizer, criterion, epochs, lr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e0ea5b-8643-405e-830f-94c1222f5ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbda7f-5b87-4a66-9db6-9cf721d573b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del model\n",
    "del optimizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00fd7d86-7c46-4664-ba42-d20307bedb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, sentence):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035422a4-a543-40d7-8d2a-5fd229a1164e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
