{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport pandas as pd\nimport numpy as np\n\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\nfrom transformers.optimization import AdamW\n\nfrom random import choice, random\n\nfrom tqdm.auto import tqdm\n\nfrom sklearn import model_selection","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:45:20.035441Z","iopub.execute_input":"2021-06-26T20:45:20.036340Z","iopub.status.idle":"2021-06-26T20:45:22.937019Z","shell.execute_reply.started":"2021-06-26T20:45:20.036219Z","shell.execute_reply":"2021-06-26T20:45:22.936084Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Подготовка данных","metadata":{}},{"cell_type":"code","source":"RANDOM_STATE = 1","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-26T20:45:22.938762Z","iopub.execute_input":"2021-06-26T20:45:22.939351Z","iopub.status.idle":"2021-06-26T20:45:22.943927Z","shell.execute_reply.started":"2021-06-26T20:45:22.939311Z","shell.execute_reply":"2021-06-26T20:45:22.943218Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/lenta-dataset/dataset.csv')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-26T20:45:22.946532Z","iopub.execute_input":"2021-06-26T20:45:22.947225Z","iopub.status.idle":"2021-06-26T20:45:35.032803Z","shell.execute_reply.started":"2021-06-26T20:45:22.947175Z","shell.execute_reply":"2021-06-26T20:45:35.031756Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.gender.replace('undefined', 'undefined_g', inplace=True)\ndf.number.replace('undefined', 'undefined_n', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:45:35.036627Z","iopub.execute_input":"2021-06-26T20:45:35.036958Z","iopub.status.idle":"2021-06-26T20:45:35.180541Z","shell.execute_reply.started":"2021-06-26T20:45:35.036928Z","shell.execute_reply":"2021-06-26T20:45:35.179708Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.tense = df.tense.apply(lambda t: np.nan if t == 'past' and random() >= 0.5 else t)\ndf.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:45:35.181954Z","iopub.execute_input":"2021-06-26T20:45:35.182320Z","iopub.status.idle":"2021-06-26T20:45:37.126129Z","shell.execute_reply.started":"2021-06-26T20:45:35.182282Z","shell.execute_reply":"2021-06-26T20:45:37.120768Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = df.sample(frac=0.2, random_state=RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:45:37.138683Z","iopub.execute_input":"2021-06-26T20:45:37.143512Z","iopub.status.idle":"2021-06-26T20:45:37.552769Z","shell.execute_reply.started":"2021-06-26T20:45:37.143480Z","shell.execute_reply":"2021-06-26T20:45:37.544989Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:45:37.573415Z","iopub.execute_input":"2021-06-26T20:45:37.581465Z","iopub.status.idle":"2021-06-26T20:45:37.606759Z","shell.execute_reply.started":"2021-06-26T20:45:37.581434Z","shell.execute_reply":"2021-06-26T20:45:37.605993Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                orig_texts  \\\n1637988  Он также пояснил, что компания не может контро...   \n1406376  Каким именно образом алкоголизм связан с видео...   \n642225   К такому выводу пришли ученые, прочитавшие ген...   \n1668448  Городок аттракционов Paradise Amusements работ...   \n1791533  В результате Клинтон потерял равновесие и пока...   \n...                                                    ...   \n197938   Глава МВД Владимир Колокольцев, прибывший в Кр...   \n1091943  По мнению экспертов, неудачные улучшения  не т...   \n552397   Мужчина по имени Джек Дэниэлс (Jack Daniel’s) ...   \n832537   Выход \"Клипперс\" в плей-офф стал возможен благ...   \n1606112  \"У Кости есть желание победить и это главное, ...   \n\n                                           part_lemm_texts  length  \\\n1637988  Он также пояснить, что компания не может контр...      27   \n1406376  какой именно образом алкоголизм связать с виде...      15   \n642225   к такой вывод прислать учёный, прочитавший ген...      20   \n1668448  городок аттракцион paradise amusements работае...      18   \n1791533  в результат Клинтон потерять равновесие и пока...      10   \n...                                                    ...     ...   \n197938   глава МВД владимир колоколец, прибывший в крат...      22   \n1091943  по мнение эксперт, неудачные улучшение не толь...      20   \n552397   мужчина по имя джек дэниэлс (jack daniel ’ s) ...      29   \n832537   выход \" клипперс \" в плей-офф стать возможный ...      22   \n1606112  \" у кость есть желание победить и это главное,...      14   \n\n                  nsubj gender tense number  \n1637988              Он   masc  past   sing  \n1406376  корреспонденты   masc  past   plur  \n642225           ученые   masc  past   plur  \n1668448         Городок   masc  pres   sing  \n1791533         Клинтон   masc  past   sing  \n...                 ...    ...   ...    ...  \n197938            Глава   masc  past   sing  \n1091943       улучшения   neut  pres   plur  \n552397          Мужчина   masc  past   sing  \n832537            Выход   masc  past   sing  \n1606112         желание   neut  pres   sing  \n\n[240858 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>orig_texts</th>\n      <th>part_lemm_texts</th>\n      <th>length</th>\n      <th>nsubj</th>\n      <th>gender</th>\n      <th>tense</th>\n      <th>number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1637988</th>\n      <td>Он также пояснил, что компания не может контро...</td>\n      <td>Он также пояснить, что компания не может контр...</td>\n      <td>27</td>\n      <td>Он</td>\n      <td>masc</td>\n      <td>past</td>\n      <td>sing</td>\n    </tr>\n    <tr>\n      <th>1406376</th>\n      <td>Каким именно образом алкоголизм связан с видео...</td>\n      <td>какой именно образом алкоголизм связать с виде...</td>\n      <td>15</td>\n      <td>корреспонденты</td>\n      <td>masc</td>\n      <td>past</td>\n      <td>plur</td>\n    </tr>\n    <tr>\n      <th>642225</th>\n      <td>К такому выводу пришли ученые, прочитавшие ген...</td>\n      <td>к такой вывод прислать учёный, прочитавший ген...</td>\n      <td>20</td>\n      <td>ученые</td>\n      <td>masc</td>\n      <td>past</td>\n      <td>plur</td>\n    </tr>\n    <tr>\n      <th>1668448</th>\n      <td>Городок аттракционов Paradise Amusements работ...</td>\n      <td>городок аттракцион paradise amusements работае...</td>\n      <td>18</td>\n      <td>Городок</td>\n      <td>masc</td>\n      <td>pres</td>\n      <td>sing</td>\n    </tr>\n    <tr>\n      <th>1791533</th>\n      <td>В результате Клинтон потерял равновесие и пока...</td>\n      <td>в результат Клинтон потерять равновесие и пока...</td>\n      <td>10</td>\n      <td>Клинтон</td>\n      <td>masc</td>\n      <td>past</td>\n      <td>sing</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>197938</th>\n      <td>Глава МВД Владимир Колокольцев, прибывший в Кр...</td>\n      <td>глава МВД владимир колоколец, прибывший в крат...</td>\n      <td>22</td>\n      <td>Глава</td>\n      <td>masc</td>\n      <td>past</td>\n      <td>sing</td>\n    </tr>\n    <tr>\n      <th>1091943</th>\n      <td>По мнению экспертов, неудачные улучшения  не т...</td>\n      <td>по мнение эксперт, неудачные улучшение не толь...</td>\n      <td>20</td>\n      <td>улучшения</td>\n      <td>neut</td>\n      <td>pres</td>\n      <td>plur</td>\n    </tr>\n    <tr>\n      <th>552397</th>\n      <td>Мужчина по имени Джек Дэниэлс (Jack Daniel’s) ...</td>\n      <td>мужчина по имя джек дэниэлс (jack daniel ’ s) ...</td>\n      <td>29</td>\n      <td>Мужчина</td>\n      <td>masc</td>\n      <td>past</td>\n      <td>sing</td>\n    </tr>\n    <tr>\n      <th>832537</th>\n      <td>Выход \"Клипперс\" в плей-офф стал возможен благ...</td>\n      <td>выход \" клипперс \" в плей-офф стать возможный ...</td>\n      <td>22</td>\n      <td>Выход</td>\n      <td>masc</td>\n      <td>past</td>\n      <td>sing</td>\n    </tr>\n    <tr>\n      <th>1606112</th>\n      <td>\"У Кости есть желание победить и это главное, ...</td>\n      <td>\" у кость есть желание победить и это главное,...</td>\n      <td>14</td>\n      <td>желание</td>\n      <td>neut</td>\n      <td>pres</td>\n      <td>sing</td>\n    </tr>\n  </tbody>\n</table>\n<p>240858 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Разбиение данных на обучающие, тестовые и валидационные","metadata":{}},{"cell_type":"code","source":"train_df, test_df = model_selection.train_test_split(df, train_size=0.9)\ntest_df, val_df = model_selection.train_test_split(test_df, test_size=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:45:37.608094Z","iopub.execute_input":"2021-06-26T20:45:37.608501Z","iopub.status.idle":"2021-06-26T20:45:37.698278Z","shell.execute_reply.started":"2021-06-26T20:45:37.608463Z","shell.execute_reply":"2021-06-26T20:45:37.697358Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Загрузка претренированной модели","metadata":{}},{"cell_type":"code","source":"model_name = \"facebook/mbart-large-50\"","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:45:37.701264Z","iopub.execute_input":"2021-06-26T20:45:37.701620Z","iopub.status.idle":"2021-06-26T20:45:37.705505Z","shell.execute_reply.started":"2021-06-26T20:45:37.701589Z","shell.execute_reply":"2021-06-26T20:45:37.704563Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = MBartForConditionalGeneration.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:45:37.707864Z","iopub.execute_input":"2021-06-26T20:45:37.708254Z","iopub.status.idle":"2021-06-26T20:46:20.449765Z","shell.execute_reply.started":"2021-06-26T20:45:37.708214Z","shell.execute_reply":"2021-06-26T20:46:20.448820Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer = MBart50TokenizerFast.from_pretrained(model_name, src_lang='ru_RU', tgt_lang='ru_RU')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:20.451191Z","iopub.execute_input":"2021-06-26T20:46:20.451529Z","iopub.status.idle":"2021-06-26T20:46:23.997513Z","shell.execute_reply.started":"2021-06-26T20:46:20.451494Z","shell.execute_reply":"2021-06-26T20:46:23.996435Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:24.004279Z","iopub.execute_input":"2021-06-26T20:46:24.004563Z","iopub.status.idle":"2021-06-26T20:46:24.011020Z","shell.execute_reply.started":"2021-06-26T20:46:24.004534Z","shell.execute_reply":"2021-06-26T20:46:24.009966Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"PreTrainedTokenizerFast(name_or_path='facebook/mbart-large-50', vocab_size=250054, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['ar_AR', 'cs_CZ', 'de_DE', 'en_XX', 'es_XX', 'et_EE', 'fi_FI', 'fr_XX', 'gu_IN', 'hi_IN', 'it_IT', 'ja_XX', 'kk_KZ', 'ko_KR', 'lt_LT', 'lv_LV', 'my_MM', 'ne_NP', 'nl_XX', 'ro_RO', 'ru_RU', 'si_LK', 'tr_TR', 'vi_VN', 'zh_CN', 'af_ZA', 'az_AZ', 'bn_IN', 'fa_IR', 'he_IL', 'hr_HR', 'id_ID', 'ka_GE', 'km_KH', 'mk_MK', 'ml_IN', 'mn_MN', 'mr_IN', 'pl_PL', 'ps_AF', 'pt_XX', 'sv_SE', 'sw_KE', 'ta_IN', 'te_IN', 'th_TH', 'tl_XX', 'uk_UA', 'ur_PK', 'xh_ZA', 'gl_ES', 'sl_SI']})"},"metadata":{}}]},{"cell_type":"code","source":"special_tokens = {\n    'masc': '<masc_g>',\n    'fem': '<fem_g>',\n    'neut': '<neut_g>',\n    'undefined_g': '<undef_g>',\n    'past': '<past_t>',\n    'pres': '<pres_t>',\n    'fut': '<fut_t>',\n    'sing': '<sing_n>',\n    'plur': '<plur_n>',\n    'undefined_n': '<undef_n>'\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:24.012692Z","iopub.execute_input":"2021-06-26T20:46:24.013055Z","iopub.status.idle":"2021-06-26T20:46:24.021286Z","shell.execute_reply.started":"2021-06-26T20:46:24.013019Z","shell.execute_reply":"2021-06-26T20:46:24.020238Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"num_added_tokens = tokenizer.add_special_tokens({'additional_special_tokens': list(special_tokens.values())})","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:24.023207Z","iopub.execute_input":"2021-06-26T20:46:24.023719Z","iopub.status.idle":"2021-06-26T20:46:24.031090Z","shell.execute_reply.started":"2021-06-26T20:46:24.023678Z","shell.execute_reply":"2021-06-26T20:46:24.030207Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.set_input_embeddings(model.resize_token_embeddings(num_added_tokens + tokenizer.vocab_size))","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:24.032723Z","iopub.execute_input":"2021-06-26T20:46:24.033162Z","iopub.status.idle":"2021-06-26T20:46:29.663613Z","shell.execute_reply.started":"2021-06-26T20:46:24.033080Z","shell.execute_reply":"2021-06-26T20:46:29.662682Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Разбиение данных на батчи","metadata":{}},{"cell_type":"code","source":"batch_size = 4","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:29.664968Z","iopub.execute_input":"2021-06-26T20:46:29.665329Z","iopub.status.idle":"2021-06-26T20:46:29.669207Z","shell.execute_reply.started":"2021-06-26T20:46:29.665291Z","shell.execute_reply":"2021-06-26T20:46:29.668230Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def make_batched_dataset(df, tokenizer=tokenizer, batch_size=batch_size):\n    n_batches = len(df) // batch_size\n    \n    for n_batch in range(n_batches):\n        \n        orig_texts   = df.orig_texts.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        lemm_texts   = df.part_lemm_texts.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        nsubj_list   = df.nsubj.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        gender_list  = df.gender.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        tense_list   = df.tense.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        number_list  = df.number.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        \n        bos_token = tokenizer.bos_token\n        eos_token = tokenizer.eos_token\n        \n        inputs = zip(lemm_texts, nsubj_list, gender_list, tense_list, number_list)\n        \n        inputs = [f'{nsubj} {special_tokens[gender]} {special_tokens[tense]} {special_tokens[number]} {bos_token} {lemm} {eos_token}'\n                  for lemm, nsubj, gender, tense, number in inputs]\n        \n        inputs = tokenizer(inputs, add_special_tokens=False, padding='longest',\n                           return_tensors='pt')\n        \n        targets = [f'{bos_token} {orig} {eos_token}' for orig in orig_texts]\n        \n        with tokenizer.as_target_tokenizer():\n            targets = tokenizer(targets, add_special_tokens=False, padding='longest',\n                                return_tensors='pt', return_attention_mask=False, return_token_type_ids=False).input_ids\n        \n        yield inputs, targets\n        ","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-26T20:46:29.670616Z","iopub.execute_input":"2021-06-26T20:46:29.671252Z","iopub.status.idle":"2021-06-26T20:46:29.685276Z","shell.execute_reply.started":"2021-06-26T20:46:29.671215Z","shell.execute_reply":"2021-06-26T20:46:29.684468Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_n_batches = len(train_df) // batch_size\nval_n_batches = len(val_df) // batch_size\ntest_n_batches = len(test_df)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:29.686678Z","iopub.execute_input":"2021-06-26T20:46:29.687069Z","iopub.status.idle":"2021-06-26T20:46:29.698682Z","shell.execute_reply.started":"2021-06-26T20:46:29.687033Z","shell.execute_reply":"2021-06-26T20:46:29.697880Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# def save_processed_data(train_data, val_data, test_data):\n#     path = {\n#         'dir': './data/cached',\n#         'name': 'processed_data_mt5.pkl'\n#     }\n    \n#     try:\n#         pathlib.Path(path['dir']).mkdir(exist_ok=True)\n#         file_path = path['dir'] + '/' + path['name']\n\n#         with open(file_path, 'wb') as f:\n#             pickle.dump((train_data, val_data, test_data), f)\n\n#         print(f'Data is saved successfully at {file_path}')\n\n#     except Exception as e:\n#         print(f'Failed to save data due to:\\n{e}')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:29.699963Z","iopub.execute_input":"2021-06-26T20:46:29.700333Z","iopub.status.idle":"2021-06-26T20:46:29.707883Z","shell.execute_reply.started":"2021-06-26T20:46:29.700298Z","shell.execute_reply":"2021-06-26T20:46:29.707135Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# def load_processed_data(path='./data/cached/processed_data_mt5.pkl'):\n#     try:\n#         with open(path, 'rb') as f:\n#             data = pickle.load(f)\n\n#         print(f'Data is loaded successfully from {path}')\n\n#         return data\n\n#     except Exception as e:\n#         print(f'Failed to load data due to:\\n{e}')\n\n#         return [None] * 3","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:29.709046Z","iopub.execute_input":"2021-06-26T20:46:29.709452Z","iopub.status.idle":"2021-06-26T20:46:29.720743Z","shell.execute_reply.started":"2021-06-26T20:46:29.709414Z","shell.execute_reply":"2021-06-26T20:46:29.719868Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_data = make_batched_dataset(train_df)\nval_data = make_batched_dataset(val_df)\ntest_data = []\nfor i, batch in enumerate(tqdm(make_batched_dataset(test_df, batch_size=1), desc='Unpacking test batches', total=500)):\n    test_data.append(batch)\n    if i == 500:\n        break\n# test_data = [batch for batch in tqdm(make_batched_dataset(test_df, batch_size=1), desc='Unpacking test batches', total=test_n_batches)]","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:29.721969Z","iopub.execute_input":"2021-06-26T20:46:29.722353Z","iopub.status.idle":"2021-06-26T20:46:30.999518Z","shell.execute_reply.started":"2021-06-26T20:46:29.722318Z","shell.execute_reply":"2021-06-26T20:46:30.998527Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Unpacking test batches:   0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455fb43c78cf48ab92a2606820acf438"}},"metadata":{}}]},{"cell_type":"code","source":"# load_data = False\n# save_data = True\n\n# if load_data:\n#     train_data, val_data, test_data = load_processed_data()\n\n# if not load_data or train_data is None:\n#     train_data = [batch for batch in tqdm(make_batched_dataset(train_df), desc='Unpacking train batches', total=train_n_batches)]\n#     val_data = [batch for batch in tqdm(make_batched_dataset(val_df), desc='Unpacking validation batches', total=val_n_batches)]\n#     test_data = [batch for batch in tqdm(make_batched_dataset(test_df, batch_size=1), desc='Unpacking test batches', total=test_n_batches)]\n\n# if save_data:\n#     save_processed_data(train_data, val_data, test_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:31.000933Z","iopub.execute_input":"2021-06-26T20:46:31.001313Z","iopub.status.idle":"2021-06-26T20:46:31.005712Z","shell.execute_reply.started":"2021-06-26T20:46:31.001274Z","shell.execute_reply":"2021-06-26T20:46:31.004607Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class BatchedDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        return self.data[idx]","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:31.007082Z","iopub.execute_input":"2021-06-26T20:46:31.007525Z","iopub.status.idle":"2021-06-26T20:46:31.017122Z","shell.execute_reply.started":"2021-06-26T20:46:31.007489Z","shell.execute_reply":"2021-06-26T20:46:31.016117Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def save_model(model, optimizer, path='./seq2seq_mbart_finetuned.model'):\n    checkpoint = {\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict()\n    }\n    \n    torch.save(checkpoint, path)\n    print(f'\\n\\tModel saved successfully at {path}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:31.018619Z","iopub.execute_input":"2021-06-26T20:46:31.019098Z","iopub.status.idle":"2021-06-26T20:46:31.029645Z","shell.execute_reply.started":"2021-06-26T20:46:31.019063Z","shell.execute_reply":"2021-06-26T20:46:31.028744Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def load_model(model, optimizer, device, path='../input/mt5-model-finetuned/seq2seq_mt5_finetuned.model'):\n    checkpoint = torch.load(path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    \n    print(f'\\n\\tModel loaded successfully from {path}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:31.030795Z","iopub.execute_input":"2021-06-26T20:46:31.031302Z","iopub.status.idle":"2021-06-26T20:46:31.039767Z","shell.execute_reply.started":"2021-06-26T20:46:31.031262Z","shell.execute_reply":"2021-06-26T20:46:31.038960Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели","metadata":{}},{"cell_type":"markdown","source":"### Определение параметров обучения","metadata":{}},{"cell_type":"code","source":"params = {\n    'learning_rate': 5e-05,\n    'epochs': 10,\n    'max_norm': 1.0,\n    'device': torch.device('cuda'),\n    'max_seq_len': 150,\n    'epochs': 5\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:31.040989Z","iopub.execute_input":"2021-06-26T20:46:31.041595Z","iopub.status.idle":"2021-06-26T20:46:31.050990Z","shell.execute_reply.started":"2021-06-26T20:46:31.041504Z","shell.execute_reply":"2021-06-26T20:46:31.050240Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# train_data = DataLoader(BatchedDataset(train_data), batch_size=None, shuffle=True, num_workers=0)\n# val_data = DataLoader(BatchedDataset(val_data), batch_size=None, shuffle=False, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:31.054502Z","iopub.execute_input":"2021-06-26T20:46:31.055011Z","iopub.status.idle":"2021-06-26T20:46:31.060986Z","shell.execute_reply.started":"2021-06-26T20:46:31.054972Z","shell.execute_reply":"2021-06-26T20:46:31.060213Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=params['learning_rate'])","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:31.064170Z","iopub.execute_input":"2021-06-26T20:46:31.064462Z","iopub.status.idle":"2021-06-26T20:46:31.077638Z","shell.execute_reply.started":"2021-06-26T20:46:31.064437Z","shell.execute_reply":"2021-06-26T20:46:31.076846Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = model.to(params['device'])","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:31.078923Z","iopub.execute_input":"2021-06-26T20:46:31.079341Z","iopub.status.idle":"2021-06-26T20:46:35.173666Z","shell.execute_reply.started":"2021-06-26T20:46:31.079304Z","shell.execute_reply":"2021-06-26T20:46:35.172765Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"load_pretrained_model = False\n\nif load_pretrained_model:\n    load_model(model, optimizer, params['device'])","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:35.175019Z","iopub.execute_input":"2021-06-26T20:46:35.175401Z","iopub.status.idle":"2021-06-26T20:46:35.180327Z","shell.execute_reply.started":"2021-06-26T20:46:35.175363Z","shell.execute_reply":"2021-06-26T20:46:35.179117Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, max_seq_len,\n          train_data, val_data, test_data,\n          epochs, max_norm, device,\n          tokenizer, model_path, n_prints=10):\n    \n    min_mean_val_loss = float('+inf')\n    print_every = train_n_batches // n_prints\n    \n    train_samples = []\n    val_samples = []\n    to_dataloader = True\n    \n    for epoch in tqdm(range(0, epochs), 'Epochs'):\n        running_train_loss = 0.0\n        print(f'\\nEpoch [{epoch} / {epochs}]')\n        \n        model.train()\n        tqdm_iter_batch = tqdm(train_data, desc='Training iterations', total=train_n_batches)\n        for iteration, (input, target) in enumerate(tqdm_iter_batch):\n            train_samples.append((input, target))\n            \n            input = {k: v.to(device) for k, v in input.items()}\n            target = target.to(device)\n            \n            optimizer.zero_grad()\n            \n            output = model(**input, labels=target)\n            \n            loss = output.loss\n            \n            running_train_loss += loss.item()\n            \n            tqdm_iter_batch.set_postfix({'train_loss': loss.item()})\n            \n            loss.backward()\n            \n#             global_step = epoch * (len(train_data) + 1) + iteration\n#             train_loss_writer.add_scalar('Training loss', loss, global_step=global_step)\n            \n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n            \n            optimizer.step()\n            \n            if iteration % print_every == 0:\n                mean_train_loss = running_train_loss / print_every if iteration != 0 else running_train_loss\n                running_train_loss = 0\n                print(f'\\n\\tIteration #{iteration}: training loss = {mean_train_loss}\\n')\n                \n                if iteration != 0:\n                    save_model(model, optimizer)\n                \n                test_sample = choice(test_data)\n                seq_len = test_sample[0].input_ids.shape[1]\n                \n                generated = model.generate(test_sample[0].input_ids.to(device), min_length=seq_len)\n\n                decoded_output = tokenizer.decode(generated[0])\n                decoded_input  = tokenizer.decode(test_sample[0].input_ids.squeeze(0))\n                decoded_target = tokenizer.decode(test_sample[1].squeeze(0))\n\n                print(f'\\tInput : {decoded_input}')\n                print(f'\\tOutput: {decoded_output}')\n                print(f'\\tTarget: {decoded_target}')\n                \n                \n            if to_dataloader:\n                train_data = DataLoader(BatchedDataset(train_samples), batch_size=None, shuffle=True)\n                val_data = DataLoader(BatchedDataset(val_samples), batch_size=None, shuffle=False)\n                to_dataloader = False","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:35.181851Z","iopub.execute_input":"2021-06-26T20:46:35.182301Z","iopub.status.idle":"2021-06-26T20:46:35.198130Z","shell.execute_reply.started":"2021-06-26T20:46:35.182265Z","shell.execute_reply":"2021-06-26T20:46:35.197318Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train(model, optimizer, params['max_seq_len'],\n      train_data, val_data, test_data,\n      params['epochs'], params['max_norm'], params['device'],\n      tokenizer, './seq2seq_mt5_finetuned.model')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T20:46:35.199174Z","iopub.execute_input":"2021-06-26T20:46:35.199562Z","iopub.status.idle":"2021-06-27T02:13:15.575849Z","shell.execute_reply.started":"2021-06-26T20:46:35.199524Z","shell.execute_reply":"2021-06-27T02:13:15.573239Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epochs:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"354e31b0fe7e4690b0d6c88811541646"}},"metadata":{}},{"name":"stdout","text":"\nEpoch [0 / 5]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training iterations:   0%|          | 0/54193 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"474e193c058c43d4902b62026717dbac"}},"metadata":{}},{"name":"stdout","text":"\n\tIteration #0: training loss = 4.643941879272461\n\n\tInput : правда <fem_g> <pres_t> <sing_n> <s> о это в среда, 9 ноября, сообщать « Украинская правда ». </s>\n\tOutput: </s><s> <fem_g> <pres_t> <unk>................... о это в среда, 9 ноября, сообщать « Украинская правда ». </s>\n\tTarget: <s> Об этом в среду, 9 ноября, сообщает «Украинская правда». </s>\n\n\tIteration #5419: training loss = 0.22350331658865583\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : я <masc_g> <past_t> <sing_n> <s> именно поэтому я хотеть вы навестить », — сказать генерал в время встреча в среда, 6 апрель, с начальником генштаб вс рф валерий герасимов. </s>\n\tOutput: </s><s> Именно поэтому я хочу вас навестить», — сказал генерал во время встречи в среду, 6 апреля, с начальником генштаба МВД РФ Валерием Герасиным. ✎✎✎✎✎✎<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>\n\tTarget: <s> Именно поэтому я хотел вас навестить», — сказал генерал во время встречи в среду, 6 апреля, с начальником Генштаба ВС РФ Валерием Герасимовым. </s>\n\n\tIteration #10838: training loss = 0.1521277438909062\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : собаки <fem_g> <pres_t> <plur_n> <s> \" Эти собака пользоваться особый популярность у человек, который не могут держать домашний животное из-за жилищный условие, а также у одинокий старик \", – сказать представитель торгующей игрушка фирма. </s>\n\tOutput: </s><s> \"Эти собаки пользуются особым популярностью у людей, которые не могут держать домашних животных из-за жилищных условий, а также у одиноких стариков\", – сказал представитель торгующей игрушек фирмы.. <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>\n\tTarget: <s> \"Эти собаки пользуются особой популярностью у людей, которые не могут держать домашних животных из-за жилищных условий, а также у одиноких стариков\", – сказал представитель торгующей игрушками фирмы. </s>\n\n\tIteration #16257: training loss = 0.13546926531742884\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : BBC <undef_g> <pres_t> <undef_n> <s> о это 19 июня пишет bbc News. </s>\n\tOutput: </s><s> Об этом 19 июня пишет BBC News. Информацию 19 июня пишет BBC News. </s>\n\tTarget: <s> Об этом 19 июня пишет BBC News. </s>\n\n\tIteration #21676: training loss = 0.12640845864528025\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : выставка <fem_g> <fut_t> <sing_n> <s> этот игровая выставка пройдет в Лос-Анжелесе в июнь. </s>\n\tOutput: </s><s> Эта игровая выставка пройдет в Лос-Анжелесе в июне,  ✎✎✎✎✎<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>\n\tTarget: <s> Эта игровая выставка пройдет в Лос-Анжелесе в июне. </s>\n\n\tIteration #27095: training loss = 0.11965347070592787\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : News <undef_g> <pres_t> <undef_n> <s> News corp также владеть news outdoor - один из крупный оператор наружный реклама в россия. </s>\n\tOutput: </s><s> News Outdoor - одним из крупнейших операторов наружной рекламы в России. 此外 владеет News Outdoor - одним из крупных операторов наружной рекламы в России. </s>\n\tTarget: <s> News Corp также владеет News Outdoor - одним из крупнейших операторов наружной рекламы в России. </s>\n\n\tIteration #32514: training loss = 0.1149183514536011\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : циклон <masc_g> <past_t> <sing_n> <s> Причиной непогода стать циклон, пришедший в столичный регион с балтика. </s>\n\tOutput: </s><s> Причиной непогоды стал циклон, пришедший в столичные регионы с балтиками пропагандой с балтиками. </s>\n\tTarget: <s> Причиной непогоды стал циклон, пришедший в столичный регион с Балтики. </s>\n\n\tIteration #37933: training loss = 0.11034610396604733\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : он <masc_g> <past_t> <sing_n> <s> о это он заявить на встреча с инициативный группа, говориться на сайт краевой администрация. </s>\n\tOutput: </s><s> Об этом он заявил на встрече с инициативной группой, говорится на сайте краевой администрации. ↩︎ об этом он заявил на встрече с инициативной группой, говорится на сайте краевой администрации. </s>\n\tTarget: <s> Об этом он заявил на встрече с инициативной группой, говорится на сайте краевой администрации. </s>\n\n\tIteration #43352: training loss = 0.1081547155655568\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : Я <masc_g> <past_t> <sing_n> <s> « я лежать на кровати Роналду, потому что знать, что он спал в она. </s>\n\tOutput: </s><s> «Я лежал на кровате Роналду, потому что знаю, что он спал в ней.. ‬‬€азнает, что он спал в ней. </s>\n\tTarget: <s> «Я лежал на кровати Роналду, потому что знал, что он спал в ней. </s>\n\n\tIteration #48771: training loss = 0.10384126486224968\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : Устройство <neut_g> <fut_t> <sing_n> <s> Устройство под названием ThinkPad tablet 2 поступит в продажу в конце октябрь, сразу после релиза самой операционный система. </s>\n\tOutput: </s><s> Устройство под названием ThinkPad Tablet 2 поступит в продажу в конце октября, сразу после релиза самой операционной системы. उदा) Устройство под названием Tablet 2 поступит в продажу в конце октября, сразу после релиза самой операционной системы. </s>\n\tTarget: <s> Устройство под названием ThinkPad Tablet 2 поступит в продажу в конце октября, сразу после релиза самой операционной системы. </s>\n\n\tIteration #54190: training loss = 0.10177037938885554\n\n\n\tModel saved successfully at ./seq2seq_mbart_finetuned.model\n\n\tInput : BBC <undef_g> <pres_t> <undef_n> <s> в четверг графиня уэссекский, супруг младший сын королева великобритания принц эдуард, была доставить в госпиталь имя король эдуард vii в центре лондон, сообщать BBC news со ссылкой на пресс-служба букингемский дворец. </s>\n\tOutput: </s><s> В четверг графиня Уэссекская, супруга младшего сына Королева Великобритании принца Эдуарда, была доставлена в госпиталь имени короля Эдуарда VIII в центре Лондона, сообщает BBC News со ссылкой на пресс-службу Букингемского дворца. Жаде, сообщает BBC News со ссылкой на пресс-службу Букингемского дворца. </s>\n\tTarget: <s> В четверг графиня Уэссекская, супруга младшего сына королевы Великобритании принца Эдуарда, была доставлена в госпиталь имени короля Эдуарда VII в центре Лондона, сообщает BBC News со ссылкой на пресс-службу Букингемского дворца. </s>\n\nEpoch [1 / 5]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training iterations:   0%|          | 0/54193 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31f1c814458842d49fafc3e46737892d"}},"metadata":{}},{"name":"stdout","text":"\n\tIteration #0: training loss = 0.07508623600006104\n\n\tInput : нарушение <neut_g> <pres_t> <sing_n> <s> по данные гибдд, именно это нарушение являться причина большинство авария с смертельный исходом. </s>\n\tOutput: </s><s> По данным ГИБДД, это нарушение является причиной большинства аварий со смертельным исходом. именно именно, помнит гибдд, это нарушение является причиной большинства аварий со смертельным. </s>\n\tTarget: <s> По данным ГИБДД, именно это нарушение является причиной большинства аварий со смертельным исходом. </s>\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-2cba735b1f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m       \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_norm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       tokenizer, './seq2seq_mt5_finetuned.model')\n\u001b[0m","\u001b[0;32m<ipython-input-31-074276261143>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, max_seq_len, train_data, val_data, test_data, epochs, max_norm, device, tokenizer, model_path, n_prints)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         )\n\u001b[1;32m   1305\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1164\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             )\n\u001b[1;32m   1168\u001b[0m         \u001b[0;31m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    801\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                         \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhead_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m                     )\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    318\u001b[0m         )\n\u001b[1;32m    319\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), './seq2seq_finetuned_mbart_inference.model')","metadata":{"execution":{"iopub.status.busy":"2021-06-27T02:15:18.420910Z","iopub.execute_input":"2021-06-27T02:15:18.421251Z","iopub.status.idle":"2021-06-27T02:15:28.142533Z","shell.execute_reply.started":"2021-06-27T02:15:18.421217Z","shell.execute_reply":"2021-06-27T02:15:28.141462Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}