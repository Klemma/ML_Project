{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Импорт необходимых зависимостей","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport nltk\n\nimport torch\nimport torch.nn as nn\nimport torch.optim\n\nimport pickle\nimport pathlib\nimport os\n\n# from torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom sklearn import model_selection\n\nfrom pprint import pprint\nfrom random import choice\nfrom typing import List, Union\nfrom collections import Counter\nfrom itertools import chain\n\nfrom tqdm.auto import tqdm\n\nfrom transformers import BertTokenizerFast","metadata":{"pycharm":{"is_executing":true},"tags":[],"execution":{"iopub.status.busy":"2021-06-26T05:34:46.864155Z","iopub.execute_input":"2021-06-26T05:34:46.864520Z","iopub.status.idle":"2021-06-26T05:34:49.409060Z","shell.execute_reply.started":"2021-06-26T05:34:46.864437Z","shell.execute_reply":"2021-06-26T05:34:49.408263Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"os.environ['CUDA_LAUNCH_BLOCKING'] = '1'","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:34:49.410526Z","iopub.execute_input":"2021-06-26T05:34:49.410847Z","iopub.status.idle":"2021-06-26T05:34:49.415355Z","shell.execute_reply.started":"2021-06-26T05:34:49.410814Z","shell.execute_reply":"2021-06-26T05:34:49.414178Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt', quiet=True);","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:34:49.417376Z","iopub.execute_input":"2021-06-26T05:34:49.417946Z","iopub.status.idle":"2021-06-26T05:34:49.736031Z","shell.execute_reply.started":"2021-06-26T05:34:49.417898Z","shell.execute_reply":"2021-06-26T05:34:49.735284Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Подготовка данных","metadata":{}},{"cell_type":"code","source":"RANDOM_STATE = 1","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-26T05:34:49.737403Z","iopub.execute_input":"2021-06-26T05:34:49.737713Z","iopub.status.idle":"2021-06-26T05:34:49.744238Z","shell.execute_reply.started":"2021-06-26T05:34:49.737688Z","shell.execute_reply":"2021-06-26T05:34:49.743492Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/lenta-dataset/dataset.csv')\ndf = df.sample(frac=0.5, random_state=RANDOM_STATE)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-26T05:34:49.745364Z","iopub.execute_input":"2021-06-26T05:34:49.745786Z","iopub.status.idle":"2021-06-26T05:35:11.193205Z","shell.execute_reply.started":"2021-06-26T05:34:49.745706Z","shell.execute_reply":"2021-06-26T05:35:11.192369Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.gender.replace('undefined', 'undefined_g', inplace=True)\ndf.number.replace('undefined', 'undefined_n', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:11.196392Z","iopub.execute_input":"2021-06-26T05:35:11.196686Z","iopub.status.idle":"2021-06-26T05:35:11.305618Z","shell.execute_reply.started":"2021-06-26T05:35:11.196661Z","shell.execute_reply":"2021-06-26T05:35:11.304865Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# df = df.sample(n=5000, random_state=RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:11.306845Z","iopub.execute_input":"2021-06-26T05:35:11.307199Z","iopub.status.idle":"2021-06-26T05:35:11.310968Z","shell.execute_reply.started":"2021-06-26T05:35:11.307163Z","shell.execute_reply":"2021-06-26T05:35:11.310091Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Разбиение данных на обучающие, тестовые и валидационные","metadata":{}},{"cell_type":"code","source":"train_df, test_df = model_selection.train_test_split(df, train_size=0.9, shuffle=True, random_state=RANDOM_STATE)\ntest_df, val_df = model_selection.train_test_split(test_df, test_size=0.5, shuffle=True, random_state=RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:11.313698Z","iopub.execute_input":"2021-06-26T05:35:11.314031Z","iopub.status.idle":"2021-06-26T05:35:11.855477Z","shell.execute_reply.started":"2021-06-26T05:35:11.313996Z","shell.execute_reply":"2021-06-26T05:35:11.854610Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Подготовка словаря","metadata":{}},{"cell_type":"code","source":"batch_size = 40","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:11.857383Z","iopub.execute_input":"2021-06-26T05:35:11.857713Z","iopub.status.idle":"2021-06-26T05:35:11.861989Z","shell.execute_reply.started":"2021-06-26T05:35:11.857678Z","shell.execute_reply":"2021-06-26T05:35:11.861073Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('DeepPavlov/rubert-base-cased')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:11.863292Z","iopub.execute_input":"2021-06-26T05:35:11.863661Z","iopub.status.idle":"2021-06-26T05:35:20.153573Z","shell.execute_reply.started":"2021-06-26T05:35:11.863627Z","shell.execute_reply":"2021-06-26T05:35:20.152716Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aefa189fd534414b9b0bb94d918f09af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40dc3186eeb449a79885ca9b15d1f87c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5286722b2cb84b849f2e6c35c7fb919e"}},"metadata":{}}]},{"cell_type":"code","source":"special_tokens = {\n    'bos_token': '[BOS]',\n    'eos_token': '[EOS]',\n    'masc': '[MASC_G]',\n    'fem': '[FEM_G]',\n    'neut': '[NEUT_G]',\n    'undefined_g': '[UNDEF_G]',\n    'past': '[PAST_T]',\n    'pres': '[PRES_T]',\n    'fut': '[FUT_T]',\n    'sing': '[SING_N]',\n    'plur': '[PLUR_N]',\n    'undefined_n': '[UNDEF_N]'\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:20.154818Z","iopub.execute_input":"2021-06-26T05:35:20.155336Z","iopub.status.idle":"2021-06-26T05:35:20.160779Z","shell.execute_reply.started":"2021-06-26T05:35:20.155285Z","shell.execute_reply":"2021-06-26T05:35:20.159598Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tokenizer.add_special_tokens({'bos_token': special_tokens['bos_token'],\n                              'eos_token': special_tokens['eos_token'],\n                              'additional_special_tokens': list(special_tokens.values())[2:]})","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:20.162408Z","iopub.execute_input":"2021-06-26T05:35:20.162819Z","iopub.status.idle":"2021-06-26T05:35:20.173824Z","shell.execute_reply.started":"2021-06-26T05:35:20.162729Z","shell.execute_reply":"2021-06-26T05:35:20.172780Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"12"},"metadata":{}}]},{"cell_type":"markdown","source":"### Разбиение данных на батчи","metadata":{}},{"cell_type":"code","source":"def make_batched_dataset(df, tokenizer=tokenizer, batch_size=batch_size):\n    n_batches = len(df) // batch_size\n    \n    for n_batch in range(n_batches):\n        \n        orig_texts   = df.orig_texts.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        lemm_texts   = df.part_lemm_texts.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        nsubj_list   = df.nsubj.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        gender_list  = df.gender.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        tense_list   = df.tense.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        number_list  = df.number.to_list()[batch_size * n_batch:batch_size * (n_batch + 1)]\n        \n        bos_token = tokenizer.bos_token\n        eos_token = tokenizer.eos_token\n        \n        inputs = zip(lemm_texts, nsubj_list, gender_list, tense_list, number_list)\n        \n        inputs = [f'{nsubj} {special_tokens[gender]} {special_tokens[tense]} {special_tokens[number]} {bos_token} {lemm} {eos_token}'\n                  for lemm, nsubj, gender, tense, number in inputs]\n        \n        inputs = tokenizer(inputs, add_special_tokens=False, padding='longest',\n                           return_tensors='pt', return_attention_mask=False, return_token_type_ids=False).input_ids\n        \n        targets = [f'{bos_token} {orig} {eos_token}' for orig in orig_texts]\n        \n        targets = tokenizer(targets, add_special_tokens=False, padding='longest',\n                            return_tensors='pt', return_attention_mask=False, return_token_type_ids=False).input_ids\n        \n        yield inputs.permute(1, 0), targets.permute(1, 0)\n        ","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-26T05:35:20.175030Z","iopub.execute_input":"2021-06-26T05:35:20.175435Z","iopub.status.idle":"2021-06-26T05:35:20.186422Z","shell.execute_reply.started":"2021-06-26T05:35:20.175399Z","shell.execute_reply":"2021-06-26T05:35:20.185593Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_n_batches = len(train_df) // batch_size\nval_n_batches = len(val_df) // batch_size\ntest_n_batches = len(test_df)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:20.187961Z","iopub.execute_input":"2021-06-26T05:35:20.188339Z","iopub.status.idle":"2021-06-26T05:35:20.199000Z","shell.execute_reply.started":"2021-06-26T05:35:20.188285Z","shell.execute_reply":"2021-06-26T05:35:20.198249Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def save_processed_data(train_data, val_data, test_data):\n    path = {\n        'dir': './',\n        'name': 'processed_data_rbt.pkl'\n    }\n    \n    try:\n        pathlib.Path(path['dir']).mkdir(exist_ok=True)\n        file_path = path['dir'] + '/' + path['name']\n\n        with open(file_path, 'wb') as f:\n            pickle.dump((train_data, val_data, test_data), f)\n\n        print(f'Data is saved successfully at {file_path}')\n\n    except Exception as e:\n        print(f'Failed to save data due to:\\n{e}')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:20.200215Z","iopub.execute_input":"2021-06-26T05:35:20.200623Z","iopub.status.idle":"2021-06-26T05:35:20.209159Z","shell.execute_reply.started":"2021-06-26T05:35:20.200588Z","shell.execute_reply":"2021-06-26T05:35:20.208362Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def load_processed_data(path='../input/transformer-vocab/processed_data_rbt.pkl'):\n    try:\n        with open(path, 'rb') as f:\n            data = pickle.load(f)\n\n        print(f'Data is loaded successfully from {path}')\n\n        return data\n\n    except Exception as e:\n        print(f'Failed to load data due to:\\n{e}')\n\n        return [None] * 3","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:20.210412Z","iopub.execute_input":"2021-06-26T05:35:20.210766Z","iopub.status.idle":"2021-06-26T05:35:20.220604Z","shell.execute_reply.started":"2021-06-26T05:35:20.210733Z","shell.execute_reply":"2021-06-26T05:35:20.219658Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# train_data = make_batched_dataset(train_df)\n# val_data = make_batched_dataset(val_df)\n# test_data = []\n# for i, batch in enumerate(tqdm(make_batched_dataset(test_df, batch_size=1), desc='Unpacking test batches', total=500)):\n#     test_data.append(batch)\n#     if i == 500:\n#         break\n# test_data = [batch for batch in tqdm(make_batched_dataset(test_df, batch_size=1), desc='Unpacking test batches', total=test_n_batches)]","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:20.221729Z","iopub.execute_input":"2021-06-26T05:35:20.222059Z","iopub.status.idle":"2021-06-26T05:35:20.229528Z","shell.execute_reply.started":"2021-06-26T05:35:20.222024Z","shell.execute_reply":"2021-06-26T05:35:20.228713Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"load_data = True\nsave_data = False\n\nif load_data:\n    train_data, val_data, test_data = load_processed_data()\n\nif not load_data or train_data is None:\n    train_data = [batch for batch in tqdm(make_batched_dataset(train_df), desc='Unpacking train batches', total=train_n_batches)]\n    val_data = [batch for batch in tqdm(make_batched_dataset(val_df), desc='Unpacking validation batches', total=val_n_batches)]\n    test_data = [batch for batch in tqdm(make_batched_dataset(test_df, batch_size=1), desc='Unpacking test batches', total=test_n_batches)]\n\nif save_data:\n    save_processed_data(train_data, val_data, test_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:20.230785Z","iopub.execute_input":"2021-06-26T05:35:20.231183Z","iopub.status.idle":"2021-06-26T05:35:35.526583Z","shell.execute_reply.started":"2021-06-26T05:35:20.231147Z","shell.execute_reply":"2021-06-26T05:35:35.521835Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Data is loaded successfully from ../input/transformer-vocab/processed_data_rbt.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"class BatchedDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        return self.data[idx]","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:35.532213Z","iopub.execute_input":"2021-06-26T05:35:35.532537Z","iopub.status.idle":"2021-06-26T05:35:35.539053Z","shell.execute_reply.started":"2021-06-26T05:35:35.532510Z","shell.execute_reply":"2021-06-26T05:35:35.537245Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_data = DataLoader(BatchedDataset(train_data), batch_size=None, shuffle=True)\nval_data = DataLoader(BatchedDataset(val_data), batch_size=None, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:35.540370Z","iopub.execute_input":"2021-06-26T05:35:35.540704Z","iopub.status.idle":"2021-06-26T05:35:35.551994Z","shell.execute_reply.started":"2021-06-26T05:35:35.540668Z","shell.execute_reply":"2021-06-26T05:35:35.551107Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Определение модели","metadata":{}},{"cell_type":"markdown","source":"### Определение класса модели","metadata":{}},{"cell_type":"code","source":"class Seq2SeqTransformer(nn.Module):\n    def __init__(self, embedding_size, nhead,\n                 num_encoder_layers, num_decoder_layers, \n                 dim_feedforward, dropout, vocab_size,\n                 max_seq_len, pad_token_id, device):\n        \n        super(Seq2SeqTransformer, self).__init__()\n        \n        self.pad_token_id = pad_token_id\n        self.max_seq_len = max_seq_len\n        self.embedding_size = embedding_size\n        \n        self.to(device)\n        \n        self.device = device\n        \n        self.word_embedding = nn.Embedding(vocab_size, embedding_size, pad_token_id)\n        self.input_pos_encoding = nn.Embedding(max_seq_len, embedding_size)\n        self.target_pos_encoding = nn.Embedding(max_seq_len, embedding_size)\n        \n        self.transformer = nn.Transformer(embedding_size, nhead, num_encoder_layers,\n                                          num_decoder_layers, dim_feedforward, dropout)\n        \n        self.fc_out = nn.Linear(embedding_size, vocab_size)\n        \n    def get_padding_mask(self, input):\n        # input shape: (seq_len, batch_size)\n        padding_mask = input.permute(1, 0) == self.pad_token_id\n        return padding_mask.to(self.device)\n    \n    def forward(self, input, target):\n        # input shape: (input_seq_len, batch_size)\n        # target shape: (target_seq_len, batch_size)\n    \n        embedded_input = self.word_embedding(input)\n        embedded_target = self.word_embedding(target)\n        # embedded_input shape: (input_seq_len, batch_size, embedding_size)\n        # embedded_target shape: (target_seq_len, batch_size, embedding_size)\n        \n        batch_size = input.shape[1]\n        \n        input_seq_len = input.shape[0]\n        target_seq_len = target.shape[0]\n    \n        input_positions = torch.arange(0, input_seq_len).unsqueeze(1).expand(input_seq_len, batch_size).to(self.device)\n        target_positions = torch.arange(0, target_seq_len).unsqueeze(1).expand(target_seq_len, batch_size).to(self.device)\n        # input_positions shape: (input_seq_len, batch_size)\n        # target_positions shape: (target_seq_len, batch_size)\n        \n        input_positions = self.input_pos_encoding(input_positions)\n        target_positions = self.target_pos_encoding(target_positions)\n        # input_positions shape: (input_seq_len, batch_size, embedding_size)\n        # target_positions shape: (target_seq_len, batch_size, embedding_size)\n        \n        embedded_input += input_positions\n        embedded_target += target_positions\n        \n        input_padding_mask = self.get_padding_mask(input)\n        target_padding_mask = self.get_padding_mask(target)\n        # input_padding_mask shape: (batch_size, input_seq_len)\n        \n        target_mask = self.transformer.generate_square_subsequent_mask(target_seq_len).to(self.device)\n        # target_mask shape: (target_seq_len, target_seq_len)\n        \n        output = self.transformer(embedded_input, embedded_target,\n                                  tgt_mask=target_mask,\n                                  src_key_padding_mask=input_padding_mask,\n                                  tgt_key_padding_mask=target_padding_mask)\n        # output shape: (target_seq_len, batch_size, embedding_size)\n        \n        output = self.fc_out(output)\n        # output shape: (target_seq_len, batch_size, vocab_size)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:35.553214Z","iopub.execute_input":"2021-06-26T05:35:35.553639Z","iopub.status.idle":"2021-06-26T05:35:35.569015Z","shell.execute_reply.started":"2021-06-26T05:35:35.553586Z","shell.execute_reply":"2021-06-26T05:35:35.568001Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Определение функций-утилит","metadata":{}},{"cell_type":"markdown","source":"### Сохранение модели","metadata":{}},{"cell_type":"code","source":"def save_model(model, optimizer, epoch, val_loss, train_loss, path='./seq2seq_transformer.model'):\n    checkpoint = {\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'epoch': epoch,\n        'val_loss': val_loss,\n        'train_loss': train_loss\n    }\n    \n    torch.save(checkpoint, path)\n    print(f'\\n\\tModel saved successfully at {path}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:35.572228Z","iopub.execute_input":"2021-06-26T05:35:35.572591Z","iopub.status.idle":"2021-06-26T05:35:35.583413Z","shell.execute_reply.started":"2021-06-26T05:35:35.572557Z","shell.execute_reply":"2021-06-26T05:35:35.582547Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Загрузка модели","metadata":{}},{"cell_type":"code","source":"def load_model(model, optimizer=None, path='../input/transformer-vocab/seq2seq_transformer.model', device=torch.device('cpu')):\n    checkpoint = torch.load(path, map_location=device)\n    \n    model.load_state_dict(checkpoint['model_state_dict'])\n    \n    if optimizer is not None:\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        \n    epoch      = checkpoint['epoch']\n    val_loss   = checkpoint['val_loss']\n    train_loss = checkpoint['train_loss']\n\n    return {'epoch': epoch, 'val_loss': val_loss, 'train_loss': train_loss}","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:35.588290Z","iopub.execute_input":"2021-06-26T05:35:35.588596Z","iopub.status.idle":"2021-06-26T05:35:35.596698Z","shell.execute_reply.started":"2021-06-26T05:35:35.588573Z","shell.execute_reply":"2021-06-26T05:35:35.595827Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Место хранения модели","metadata":{}},{"cell_type":"code","source":"model_path = {\n    'dir': './',\n    'name': 'seq2seq_transformer.model'\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:35.598339Z","iopub.execute_input":"2021-06-26T05:35:35.598802Z","iopub.status.idle":"2021-06-26T05:35:35.605070Z","shell.execute_reply.started":"2021-06-26T05:35:35.598767Z","shell.execute_reply":"2021-06-26T05:35:35.604314Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели","metadata":{}},{"cell_type":"markdown","source":"### Определение параметров обучения","metadata":{}},{"cell_type":"code","source":"learning_params = {\n    'learning_rate': 5e-05,\n    'epochs': 10,\n    'max_norm': 1.0,\n    'patience': 3\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:35.606328Z","iopub.execute_input":"2021-06-26T05:35:35.606669Z","iopub.status.idle":"2021-06-26T05:35:35.614594Z","shell.execute_reply.started":"2021-06-26T05:35:35.606618Z","shell.execute_reply":"2021-06-26T05:35:35.613744Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Определение параметров сети","metadata":{}},{"cell_type":"code","source":"params = {\n    'embedding_size': 512,\n    'nhead': 8,\n    'num_encoder_layers': 4,\n    'num_decoder_layers': 4,\n    'dim_feedforward': 2048,\n    'dropout': 0.1,\n    'vocab_size': len(tokenizer.get_vocab()),\n    'max_seq_len': 110,\n    'pad_token_id': tokenizer.pad_token_id,\n    'device': torch.device('cuda')\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:35.617518Z","iopub.execute_input":"2021-06-26T05:35:35.617990Z","iopub.status.idle":"2021-06-26T05:35:35.732723Z","shell.execute_reply.started":"2021-06-26T05:35:35.617957Z","shell.execute_reply":"2021-06-26T05:35:35.731763Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Инициализация модели, оптимизатора и функции потерь","metadata":{}},{"cell_type":"code","source":"model = Seq2SeqTransformer(**params).to(params['device'])","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:35.738100Z","iopub.execute_input":"2021-06-26T05:35:35.738388Z","iopub.status.idle":"2021-06-26T05:35:41.314172Z","shell.execute_reply.started":"2021-06-26T05:35:35.738354Z","shell.execute_reply":"2021-06-26T05:35:41.313330Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=learning_params['learning_rate'])","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:41.315420Z","iopub.execute_input":"2021-06-26T05:35:41.315819Z","iopub.status.idle":"2021-06-26T05:35:41.325214Z","shell.execute_reply.started":"2021-06-26T05:35:41.315781Z","shell.execute_reply":"2021-06-26T05:35:41.323862Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=params['pad_token_id'])","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:41.326572Z","iopub.execute_input":"2021-06-26T05:35:41.327488Z","iopub.status.idle":"2021-06-26T05:35:41.342162Z","shell.execute_reply.started":"2021-06-26T05:35:41.327445Z","shell.execute_reply":"2021-06-26T05:35:41.341230Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"load_pretrained_model = True\ntrain_state = None\n\nif load_pretrained_model:\n    try:\n        train_state = load_model(\n            model, optimizer,\n            '../input/transformer-vocab/seq2seq_transformer.model',\n            params['device']\n        )\n        print(f\"Model loaded successfully from ../input/transformer-vocab/seq2seq_transformer.model\")\n    \n    except Exception as e:\n        print(f'Load failed due to:\\n{e}')\n\nepoch = train_state['epoch'] if train_state is not None else 0","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:41.343882Z","iopub.execute_input":"2021-06-26T05:35:41.344584Z","iopub.status.idle":"2021-06-26T05:35:56.791721Z","shell.execute_reply.started":"2021-06-26T05:35:41.344548Z","shell.execute_reply":"2021-06-26T05:35:56.790894Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Model loaded successfully from ../input/transformer-vocab/seq2seq_transformer.model\n","output_type":"stream"}]},{"cell_type":"code","source":"# train_loss_writer = SummaryWriter('./runs/loss')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:56.792930Z","iopub.execute_input":"2021-06-26T05:35:56.793263Z","iopub.status.idle":"2021-06-26T05:35:56.797962Z","shell.execute_reply.started":"2021-06-26T05:35:56.793228Z","shell.execute_reply":"2021-06-26T05:35:56.796816Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def evaluate(test_sample, tokenizer, max_seq_len, device):\n    predictions = [tokenizer.bos_token_id]\n    for i in range(max_seq_len):\n        target = torch.tensor(predictions, device=device).unsqueeze(1)\n        \n        output = model(test_sample.to(device), target)\n        best_prediction = output.argmax(2)[-1].item()\n        predictions.append(best_prediction)\n        \n        if best_prediction == tokenizer.eos_token_id:\n            break\n    \n    decoded_output = tokenizer.decode(predictions, return_tokenized=False)\n    return decoded_output","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:56.799435Z","iopub.execute_input":"2021-06-26T05:35:56.799805Z","iopub.status.idle":"2021-06-26T05:35:56.808447Z","shell.execute_reply.started":"2021-06-26T05:35:56.799772Z","shell.execute_reply":"2021-06-26T05:35:56.807650Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Train-скрипт","metadata":{}},{"cell_type":"code","source":"def train(\n    model, optimizer, criterion,\n    train_data, val_data, test_data,\n    epochs, max_norm, patience, current_epoch,\n    device, tokenizer, model_path, max_seq_len, n_prints=10\n):\n    \n    min_mean_val_loss = float('+inf')\n    initial_patience = patience\n    print_every = train_n_batches // n_prints\n    \n#     train_samples = []\n#     val_samples = []\n#     make_data_loaders = True\n    \n    for epoch in tqdm(range(current_epoch, epochs), 'Epochs'):\n#         try:\n        running_train_loss = 0.0\n        print(f'\\nEpoch [{epoch} / {epochs}]')\n\n        model.train()\n        tqdm_iter_batch = tqdm(train_data, desc='Training iterations', total=train_n_batches)\n        for iteration, (input, target) in enumerate(tqdm_iter_batch):\n#             train_samples.append((input, target))\n\n            input  = input.to(device)\n            target = target.to(device)\n            # input shape : (input_seq_len, batch_size)\n            # target shape: (target_seq_len, batch_size)\n\n            optimizer.zero_grad()\n\n            output = model(input, target[:-1])\n            # output shape: (target_seq_len, batch_size, vocab_size)\n\n            vocab_size = output.shape[2]\n\n            output = output.reshape(-1, vocab_size)\n            # output shape: (target_seq_len * batch_size, vocab_size)\n\n            target = target[1:].reshape(-1)\n            # target shape: (target_seq_len * batch_size)\n\n            loss = criterion(output, target)\n\n            running_train_loss += loss.item()\n\n            tqdm_iter_batch.set_postfix({'train_loss': loss.item()})\n\n            loss.backward()\n\n#             global_step = epoch * (len(train_data) + 1) + iteration\n#             train_loss_writer.add_scalar('Training loss', loss, global_step=global_step)\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n\n            optimizer.step()\n\n            if iteration % print_every == 0:\n                mean_train_loss = running_train_loss / print_every if iteration != 0 else running_train_loss\n                running_train_loss = 0\n                print(f'\\tIteration #{iteration}: training loss = {mean_train_loss}\\n')\n                \n                if iteration != 0:\n                    save_model(model, optimizer, epoch, -1, mean_train_loss)\n                \n                    test_sample = choice(test_data)\n\n                    decoded_output = evaluate(test_sample[0], tokenizer, max_seq_len, device)\n                    decoded_input  = tokenizer.decode(test_sample[0].squeeze(1))\n                    decoded_target = tokenizer.decode(test_sample[1].squeeze(1))\n\n                    print(f'\\tInput : {decoded_input}')\n                    print(f'\\tOutput: {decoded_output}')\n                    print(f'\\tTarget: {decoded_target}')\n\n\n        with torch.no_grad():\n            model.eval()\n\n            val_loss = []\n\n            for iteration, (input, target) in enumerate(tqdm(val_data, desc='Validating iterations', total=val_n_batches)):\n#                 val_samples.append((input, target))\n\n                input  = input.to(device)\n                target = target.to(device)\n\n                output = model(input, target[:-1])\n                vocab_size = output.shape[2]\n                output = output.reshape(-1, vocab_size)\n\n                target = target[1:].reshape(-1)\n\n                local_val_loss = criterion(output, target)\n                val_loss.append(local_val_loss.item())\n\n            mean_val_loss = sum(val_loss) / len(val_loss)\n            print(f'\\tValidation loss = {mean_val_loss}')\n\n            if mean_val_loss < min_mean_val_loss:\n                try:\n                    save_model(model, optimizer, epoch, mean_val_loss, loss)\n                    min_mean_val_loss = mean_val_loss\n                    patience = initial_patience\n                except Exception as e:\n                    print(f'Model saving failed due to unhandled exception:\\n{e}')\n            else:\n                patience -= 1\n\n\n#                 if make_data_loaders:\n#                     train_data = DataLoader(BatchedDataset(train_samples), batch_size=None, shuffle=True)\n#                     val_data = DataLoader(BatchedDataset(val_samples), batch_size=None, shuffle=False)\n#                     make_data_loaders = False\n\n\n            test_sample = choice(test_data)\n\n            decoded_output = evaluate(test_sample[0], tokenizer, max_seq_len, device)\n            decoded_input  = tokenizer.decode(test_sample[0].squeeze(1))\n            decoded_target = tokenizer.decode(test_sample[1].squeeze(1))\n\n            print(f'\\tInput : {decoded_input}')\n            print(f'\\tOutput: {decoded_output}')\n            print(f'\\tTarget: {decoded_target}')\n\n        if patience == 0:\n            print(f'\\nModel learning finished due to early stopping')\n            break\n#         except Exception as e:\n#             print(f'Learning stopped due to unhandled exception:\\n{e}')\n#             save_model(model, optimizer, epoch, mean_val_loss, loss)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:56.809733Z","iopub.execute_input":"2021-06-26T05:35:56.810070Z","iopub.status.idle":"2021-06-26T05:35:56.828959Z","shell.execute_reply.started":"2021-06-26T05:35:56.810039Z","shell.execute_reply":"2021-06-26T05:35:56.828173Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train(\n    model, optimizer, criterion,\n    train_data, val_data, test_data,\n    learning_params['epochs'], learning_params['max_norm'],\n    learning_params['patience'], epoch, params['device'], tokenizer,\n    model_path['dir'] + model_path['name'], params['max_seq_len']\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T05:35:56.830036Z","iopub.execute_input":"2021-06-26T05:35:56.830530Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epochs:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b0a55673c7947e5935ea55b94854b00"}},"metadata":{}},{"name":"stdout","text":"\nEpoch [3 / 10]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training iterations:   0%|          | 0/20651 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9add4b22875241ebbe9e28c6b2a98ae5"}},"metadata":{}},{"name":"stdout","text":"\tIteration #0: training loss = 0.1401817798614502\n\n\tIteration #2065: training loss = 0.20392846738960205\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : эксперты [MASC_G] [PRES_T] [PLUR_N] [BOS] об это говориться в обзор компании \" азбука жилье \". эксперт отмечают, что в ноябре рынок продемонстрировать традиционныи рост покупательскии активность : незначительно, но вырасти потенциальныи спрос, увеличиться число реальныи сделка. [EOS]\n\tOutput: [BOS] об этом говорится в обзоре компании \" азбука жилья \". эксперты отмечают, что в ноябре рынок продемонструют традиционныи рост покупательскои активности : незначительно, но вырасти потенциальныи спрос, увеличатся число реальных сделок. [EOS]\n\tTarget: [BOS] об этом говорится в обзоре компании \" азбука жилья \". эксперты отмечают, что в ноябре рынок продемонстрировал традиционныи рост покупательскои активности : незначительно, но вырос потенциальныи спрос, увеличилось число реальных сделок. [EOS]\n\tIteration #4130: training loss = 0.20456337873929928\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : глава [MASC_G] [PAST_T] [SING_N] [BOS] глава чеченскои республики рамзан кадыров объявить о тот, что эстрадныи певец николаи басков и « мисс россия 2003 » виктория лопырев сыграют свадьба в грозном. [EOS]\n\tOutput: [BOS] глава чеченскои республики рамзан кадыров объявил о том, что эстрадныи певец николаи басков и « мисс россия 2003 » виктория лопырева сыграют свадьба в грозном. [EOS]\n\tTarget: [BOS] глава чеченскои республики рамзан кадыров объявил о том, что эстрадныи певец николаи басков и « мисс россия 2003 » виктория лопырева сыграют свадьбу в грозном. [EOS]\n\tIteration #6195: training loss = 0.20392573740306258\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : партизан [MASC_G] [PAST_T] [SING_N] [BOS] свои решение партизан с 25 - летнии стаж аргументировать тем, что \" мы жить в исламскии стране по закон шариата, а потому должны подчиняться правительству \". [EOS]\n\tOutput: [BOS] свое решение партизан с 25 - летним стажем аргументировали тем, что \" мы живем в исламскои стране по закону шариата, а потому должны подчиняться правительству \". [EOS]\n\tTarget: [BOS] свое решение партизан с 25 - летним стажем аргументировал тем, что \" мы живем в исламскои стране по законам шариата, а потому должны подчиняться правительству \". [EOS]\n\tIteration #8260: training loss = 0.20303707055693387\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : сотрудники [MASC_G] [PAST_T] [PLUR_N] [BOS] возле смоленскии площади в центре москвы сотрудник правоохранительныи орган столица заблокировать автоколонну из 15 - 20 джип с армянскими флагами. [EOS]\n\tOutput: [BOS] возле смоленскои площади в центре москвы сотрудники правоохранительных органов столицы заблокировалионнуонну из 15 - 20 джипа с зарубежными флагами. [EOS]\n\tTarget: [BOS] возле смоленскои площади в центре москвы сотрудники правоохранительных органов столицы заблокировали автоколонну из 15 - 20 джипов с армянскими флагами. [EOS]\n\tIteration #10325: training loss = 0.20304678746343524\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : франция [FEM_G] [PAST_T] [SING_N] [BOS] также впереди бразилец оказаться франция, которыи с 15 - го места подняться на 13 - е. [EOS]\n\tOutput: [BOS] также впереди бразильца оказалась франция, которая с 15 - го места поднялась на 13 - е. [EOS]\n\tTarget: [BOS] также впереди бразильцев оказалась франция, которая с 15 - го места поднялась на 13 - е. [EOS]\n\tIteration #12390: training loss = 0.20177947495304066\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : предприниматель [MASC_G] [PAST_T] [SING_N] [BOS] по данные служба безопасность украина, предприниматель доставить груз общим вес 57 тонна в порт одесса. [EOS]\n\tOutput: [BOS] по данным службы безопасности украины, предприниматель доставил груз общим весом 57 тонн в порту одессы. [EOS]\n\tTarget: [BOS] по данным службы безопасности украины, предприниматель доставил груз общим весом 57 тонн в порт одессы. [EOS]\n\tIteration #14455: training loss = 0.20015808344969738\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : агентство [NEUT_G] [PRES_T] [SING_N] [BOS] солист группа depeche mode дэвид гаан вечером во вторник быть доставить в афинскии больница, передает агентство reuters. [EOS]\n\tOutput: [BOS] солист группы depeche mode дэвид гаан вечером во вторник был доставлен в афинскую больницу, передает агентство reuters. [EOS]\n\tTarget: [BOS] солист группы depeche mode дэвид гаан вечером во вторник был доставлен в афинскую больницу, передает агентство reuters. [EOS]\n\tIteration #16520: training loss = 0.20013118125408094\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : президент [MASC_G] [PAST_T] [SING_N] [BOS] президент рф владимир путин подписать закон, регулирующии рынок форекс. [EOS]\n\tOutput: [BOS] президент рф владимир путин подписал закон, регулирующии рынок форекс. [EOS]\n\tTarget: [BOS] президент рф владимир путин подписал закон, регулирующии рынок форекс. [EOS]\n\tIteration #18585: training loss = 0.19719722627078073\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : решение [NEUT_G] [PRES_T] [SING_N] [BOS] такои решение лишать владимир буковскии, имеющего, кроме россииского, еще и гражданство великобритания, права участвовать в президентскии избирательнои кампании. [EOS]\n\tOutput: [BOS] такое решение лишает владимира буковского, имеющего, кроме россииского, еще и гражданства великобритании, права участвовать в президентскои избирательнои кампании. [EOS]\n\tTarget: [BOS] такое решение лишает владимира буковского, имеющего, кроме россииского, еще и гражданство великобритании, права участвовать в президентскои избирательнои кампании. [EOS]\n\tIteration #20650: training loss = 0.19500886949081397\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : адвокат [MASC_G] [PRES_T] [SING_N] [BOS] адвокат бывшии главы краза анатолия быкова генрих падва в близкии время мочь покинуть россия, опасаться месть своего подзащитного в случаи вынесения серьезныи обвинительныи приговора. [EOS]\n\tOutput: [BOS] адвокат бывшего главы краза анатолия быкова генрих падва в ближаишее время может покинуть россию, опасаясь мести своего подзащитного в случае вынесения серьезного обвинительного приговора. [EOS]\n\tTarget: [BOS] адвокат бывшего главы краза анатолия быкова генрих падва в ближаишее время может покинуть россию, опасаясь мести своего подзащитного в случае вынесения серьезного обвинительного приговора. [EOS]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating iterations:   0%|          | 0/1147 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd1373001a8142059bb360be2dda6a5b"}},"metadata":{}},{"name":"stdout","text":"\tValidation loss = 0.18644570824937812\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : полузащитник [MASC_G] [PAST_T] [SING_N] [BOS] первыи мяч прямым ударом с штрафного на 73 - и минуте забить полузащитник « три лев » эрик даиер. [EOS]\n\tOutput: [BOS] первыи мяч прямым ударом со штрафного на 73 - и минуте забил полузащитник « три львов » эрик даиер. [EOS]\n\tTarget: [BOS] первыи мяч прямым ударом со штрафного на 73 - и минуте забил полузащитник « трех львов » эрик даиер. [EOS]\n\nEpoch [4 / 10]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training iterations:   0%|          | 0/20651 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a90d7b82fc894e8eadcd21f822e6144a"}},"metadata":{}},{"name":"stdout","text":"\tIteration #0: training loss = 0.1354968100786209\n\n\tIteration #2065: training loss = 0.16903956515520593\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : националист [MASC_G] [PAST_T] [SING_N] [BOS] эстонскии националист юри бем, которыи некоторыи время назад быть исключить из каитселиит ( военизированныи формирование, состоящии из доброволец ), добиться отмена это решение, сообщать delfi. [EOS]\n\tOutput: [BOS] эстонскии националист юри бем, которыи некоторое время назад был исключен из каитселиита ( военизированные формирования, состоящии из добровольцев ), добился отмены этого решения, сообщает delfi. [EOS]\n\tTarget: [BOS] эстонскии националист юри бем, которыи некоторое время назад был исключен из каитселиита ( военизированного формирования, состоящего из добровольцев ), добился отмены этого решения, сообщает delfi. [EOS]\n\tIteration #4130: training loss = 0.1712283521241195\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : мужчина [MASC_G] [PAST_T] [SING_N] [BOS] на станция московскии метро \" полянка \" на рельс упал мужчина, сообщать 16 февраль агентство \" интерфакс \". [EOS]\n\tOutput: [BOS] на станции московского метро \" полянка \" на рельсы упал мужчина, сообщает 16 февраля агентство \" интерфакс \". [EOS]\n\tTarget: [BOS] на станции московского метро \" полянка \" на рельсы упал мужчина, сообщает 16 февраля агентство \" интерфакс \". [EOS]\n\tIteration #6195: training loss = 0.1711029986925333\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : агентство [NEUT_G] [PAST_T] [SING_N] [BOS] о это сообщить агентство wenn с ссылка на британскии газета news of the world. [EOS]\n\tOutput: [BOS] об этом сообщило агентство wenn со ссылкои на британскую газету news of the world. [EOS]\n\tTarget: [BOS] об этом сообщило агентство wenn со ссылкои на британскую газету news of the world. [EOS]\n\tIteration #8260: training loss = 0.17084992933504228\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : человек [MASC_G] [PAST_T] [PLUR_N] [BOS] согласно последнии данным, жертва трагедия стать 159 человек, сообщать нтв. [EOS]\n\tOutput: [BOS] согласно последним данным, жертвами трагедии стали 159 человек, сообщает нтв. [EOS]\n\tTarget: [BOS] согласно последним данным, жертвами трагедии стали 159 человек, сообщает нтв. [EOS]\n\tIteration #10325: training loss = 0.17062844997023843\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : ген [MASC_G] [PAST_T] [SING_N] [BOS] ген, хранившии информация о эволюция род, исчезнуть 52 - 50 миллион год назад, в время палеоценов - эоценовыи температурныи максимум. [EOS]\n\tOutput: [BOS] ген, хранившии информацию об эволюции род, исчез 52 - 50 миллионов лет назад, во время палеоценов - эоценового температурного максимума. [EOS]\n\tTarget: [BOS] ген, хранившии информацию об эволюции рода, исчез 52 - 50 миллионов лет назад, во время палеоценово - эоценового температурного максимума. [EOS]\n\tIteration #12390: training loss = 0.1720660433966946\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : компания [FEM_G] [PRES_T] [SING_N] [BOS] датская пивоваренныи компания carlsberg планировать увеличить объем продажа в азия, чтобы снизить зависимость от нестабильныи россиискии рынок. [EOS]\n\tOutput: [BOS] датская пивоваренная компания carlsberg планирует увеличить объем продаж в азии, чтобы снизить зависимость от нестабильного россииского рынка. [EOS]\n\tTarget: [BOS] датская пивоваренная компания carlsberg планирует увеличить объем продаж в азии, чтобы снизить зависимость от нестабильного россииского рынка. [EOS]\n\tIteration #14455: training loss = 0.17043280884731768\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : риа [NEUT_G] [PRES_T] [SING_N] [BOS] дорогои спортивныи автомобиль ferrari - f 550 был угнать неизвестными злоумышленниками на северо - запад москва, сообщать риа \" новость \" со ссылка на гувд москвы. [EOS]\n\tOutput: [BOS] дорогои спортивныи автомобиль ferrari - f0 был угнан неизвестными злоумышленниками на северо - западе москвы, сообщает риа \" новости \" со ссылкои на гувд москвы. [EOS]\n\tTarget: [BOS] дорогои спортивныи автомобиль ferrari - f550 был угнан неизвестными злоумышленниками на северо - западе москвы, сообщает риа \" новости \" со ссылкои на гувд москвы. [EOS]\n\tIteration #16520: training loss = 0.1707674025875893\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : techcrunch [UNDEF_G] [PRES_T] [UNDEF_N] [BOS] этот данныи представить в отчет о рынок сми ( media survey 2010 ), писать techcrunch. [EOS]\n\tOutput: [BOS] эти данные представлены в отчетах о рынке сми ( media survey 2010 ), пишет techcrunch. [EOS]\n\tTarget: [BOS] эти данные представлены в отчете о рынке сми ( media survey 2010 ), пишет techcrunch. [EOS]\n\tIteration #18585: training loss = 0.16910325306451926\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : житель [MASC_G] [PAST_T] [SING_N] [BOS] юныи житель город тусон, штат аризона, смастерить для частично парализованныи крольчонок, которого он и он родитель нашли в двор свои дом, специальныи инвалидныи тележка. [EOS]\n\tOutput: [BOS] юныи житель города тусон, штат аризона, смастерил для частично парализованныи крольчонок, которого его и его родители нашли во дворе своего дома, специальные инвалиднои тележки. [EOS]\n\tTarget: [BOS] юныи житель города тусон, штат аризона, смастерил для частично парализованного крольчонка, которого он и его родители нашли во дворе своего дома, специальную инвалидную тележку. [EOS]\n\tIteration #20650: training loss = 0.16980249558104152\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : педагог [MASC_G] [PAST_T] [SING_N] [BOS] педагог сделать замечание юноша, которыи сидел в наушник на лекция, однако тот никак не отреагировал. [EOS]\n\tOutput: [BOS] педагог сделал замечание юноше, которыи сидел в наушниках на лекции, однако те никак не отреагировал. [EOS]\n\tTarget: [BOS] педагог сделал замечание юноше, которыи сидел в наушниках на лекции, однако тот никак не отреагировал. [EOS]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating iterations:   0%|          | 0/1147 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e48e52b7ed174d0e9268d94a565269bb"}},"metadata":{}},{"name":"stdout","text":"\tValidation loss = 0.16834916819435883\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : участники [MASC_G] [PAST_T] [PLUR_N] [BOS] их участник обсуждали результаты социологическии опрос, также быть озвучить фамилия другои возможныи кандидат. [EOS]\n\tOutput: [BOS] их участники обсуждали результаты социологических опросов, также были озвучены фамилии других возможных кандидатов. [EOS]\n\tTarget: [BOS] их участники обсуждали результаты социологических опросов, также были озвучены фамилии других возможных кандидатов. [EOS]\n\nEpoch [5 / 10]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training iterations:   0%|          | 0/20651 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02d142dd0ce944ea87be033d3861f671"}},"metadata":{}},{"name":"stdout","text":"\tIteration #0: training loss = 0.1615220159292221\n\n\tIteration #2065: training loss = 0.14302991716682767\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : танигути [FEM_G] [PAST_T] [SING_N] [BOS] 43 - летнии танигути совершать восхождение на скалу высота 1984 метра вместе с четырьмя альпинист. [EOS]\n\tOutput: [BOS] 43 - летняя танигути совершала восхождение на скалу высотах 1984 метра вместе с четырьмя альпинистами. [EOS]\n\tTarget: [BOS] 43 - летняя танигути совершала восхождение на скалу высотои 1984 метра вместе с четырьмя альпинистами. [EOS]\n\tIteration #4130: training loss = 0.14424578313677422\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : представители [MASC_G] [PAST_T] [PLUR_N] [BOS] представитель движение сопротивление африканер ( awb ) отказались мстить за свои лидер юджина тербланша ( eugene terreblanche ), убитого на прошлои неделе в юар. [EOS]\n\tOutput: [BOS] представители движения сопротивления африканских ( awb ) отказались мстить за своего лидера юджина тербланшу ( eugene terreblanche ), убитого на прошлои неделе в юар. [EOS]\n\tTarget: [BOS] представители движения сопротивления африканеров ( awb ) отказались мстить за своего лидера юджина тербланша ( eugene terreblanche ), убитого на прошлои неделе в юар. [EOS]\n\tIteration #6195: training loss = 0.14649604359781482\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : снегопад [MASC_G] [FUT_T] [SING_N] [BOS] по прогноз синоптик, в ночь с понедельник на вторник в москва поити снегопад с метель. [EOS]\n\tOutput: [BOS] по прогнозам синоптиков, в ночь с понедельника на вторник в москве поидет снегопад с метель. [EOS]\n\tTarget: [BOS] по прогнозам синоптиков, в ночь с понедельника на вторник в москве поидет снегопад с метелью. [EOS]\n\tIteration #8260: training loss = 0.14772162612428388\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : зарплата [FEM_G] [PRES_T] [SING_N] [BOS] среднии зарплата в белоруссия мочь достигнуть 1, 5 тысяча рубль ( 770 доллар по текущии курс ). [EOS]\n\tOutput: [BOS] средняя зарплата в белоруссии может достичь 1, 5 тысячи рублеи ( 770 долларов по текущему курсу ). [EOS]\n\tTarget: [BOS] средняя зарплата в белоруссии может достичь 1, 5 тысячи рублеи ( 770 долларов по текущему курсу ). [EOS]\n\tIteration #10325: training loss = 0.14956650194186563\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : сумма [FEM_G] [PRES_T] [SING_N] [BOS] таким образом, общая сумма сделка достигает 12 миллиард долларов. [EOS]\n\tOutput: [BOS] таким образом, общая сумма сделки достигает 12 миллиардов долларов. [EOS]\n\tTarget: [BOS] таким образом, общая сумма сделки достигает 12 миллиардов долларов. [EOS]\n\tIteration #12390: training loss = 0.14890877905394206\n\n\n\tModel saved successfully at ./seq2seq_transformer.model\n\n\tInput : власти [FEM_G] [PAST_T] [PLUR_N] [BOS] власти днр объявили в понедельник, 21 июль, о перемирие в 40 - километровои зона вокруг место падение « боинг », сообщать риа новости с ссылкои на премьер - министра днр александра бородая. [EOS]\n\tOutput: [BOS] власти днр объявили в понедельник, 21 июля, о перемирии в 40 - километровои зоне вокруг места падения « боинга », сообщает риа новости со ссылкои на премьер - министра днр александра бородая. [EOS]\n\tTarget: [BOS] власти днр объявили в понедельник, 21 июля, о перемирие в 40 - километровои зоне вокруг места падения « боинга », сообщает риа новости со ссылкои на премьер - министра днр александра бородая. [EOS]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}